{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Extracting feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import argparse\n",
    "import subprocess\n",
    "import matplotlib\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import shlex\n",
    "import shutil\n",
    "import glob\n",
    "import pickle\n",
    "import csv\n",
    "import operator\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from collections import defaultdict\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from Bio import SeqIO\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import preprocessing\n",
    "import pybedtools as pbt\n",
    "import pyBigWig as pbw\n",
    "from datetime import date\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import chain\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from adjustText import adjust_text\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LEUTX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FBXL19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZFAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZSCAN2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LEF1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>ZNF845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>ZNF683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>ZNF775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>ZNF57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>ZNF836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0     LEUTX\n",
       "1    FBXL19\n",
       "2      ZFAT\n",
       "3    ZSCAN2\n",
       "4      LEF1\n",
       "..      ...\n",
       "134  ZNF845\n",
       "135  ZNF683\n",
       "136  ZNF775\n",
       "137   ZNF57\n",
       "138  ZNF836\n",
       "\n",
       "[139 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = \"/Users/pavel/Desktop/MEX-ArChIPelago/\" \n",
    "basicdir = os.path.abspath('GHTS/')\n",
    "outputdir = os.path.abspath('GHTS/outputdir')\n",
    "train_dir = os.path.abspath('GHTS/Train/') \n",
    "test_dir = os.path.abspath('GHTS/Test/') \n",
    "\n",
    "if not os.path.exists(basicdir): \n",
    "    os.makedirs(basicdir)\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "\n",
    "TFs_CHS_AFS = pd.read_csv(\"./Input_data/best_20_motif_CHS_GHTS.txt\", sep=\"\\t\", header=None)\n",
    "TFs_CHS_AFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "from typing import List\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class Scorer(metaclass=ABCMeta):\n",
    "    name: str\n",
    "    @abstractmethod\n",
    "    def score(self, *args, **kwargs) -> float:\n",
    "        pass\n",
    "\n",
    "@dataclass\n",
    "class ConstantScorer(Scorer):\n",
    "    const: float\n",
    "    def score(self, *args, **kwargs) -> float:\n",
    "        return self.const\n",
    "\n",
    "class BinaryScorer(Scorer):\n",
    "    @abstractmethod\n",
    "    def score(self, y_score: List[float], y_real: List[int]) -> float:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class SklearnScorer(BinaryScorer):\n",
    "    pass\n",
    "\n",
    "class SklearnROCAUC(SklearnScorer):\n",
    "    def score(self, y_score: List[float], y_real: List[int]) -> float:\n",
    "        y_score_arr = np.array(y_score)\n",
    "        y_real_arr = np.array(y_real)\n",
    "        return float(roc_auc_score(y_true=y_real_arr, y_score=y_score_arr))\n",
    "    \n",
    "class SklearnPRAUC(SklearnScorer):\n",
    "    def score(self, y_score: List[float], y_real: List[int]) -> float:\n",
    "        y_score_arr = np.array(y_score)\n",
    "        y_real_arr = np.array(y_real)\n",
    "        return float(average_precision_score(y_true=y_real_arr, y_score=y_score_arr))\n",
    "\n",
    "class PRROCScorer(BinaryScorer):\n",
    "    pass\n",
    "\n",
    "def import_PRROC():\n",
    "    '''\n",
    "    import PRROC package (https://cran.r-project.org/web/packages/PRROC/index.html)\n",
    "    '''\n",
    "    from rpy2.robjects.packages import importr, isinstalled\n",
    "    if not isinstalled(\"PRROC\"):\n",
    "        utils = importr(\"utils\")\n",
    "        utils.chooseCRANmirror(ind=1)\n",
    "        utils.install_packages(\"PRROC\", quiet = True, verbose=False)\n",
    "    pkg = importr(\"PRROC\")\n",
    "    return pkg\n",
    "\n",
    "@dataclass\n",
    "class PRROC_PRAUC(PRROCScorer):\n",
    "    type: str\n",
    "\n",
    "    def score(self, y_score: List[float], y_real: List[int]) -> float:\n",
    "        from rpy2.rinterface_lib import openrlib\n",
    "        with openrlib.rlock:\n",
    "            pkg = import_PRROC()\n",
    "            from rpy2.robjects.vectors import FloatVector\n",
    "            labels = FloatVector([x for x in y_real])\n",
    "            scores = FloatVector(y_score)\n",
    "            if self.type == \"integral\":\n",
    "                auroc = pkg.pr_curve(scores, weights_class0=labels, dg_compute=False)\n",
    "                auroc = auroc[1][0]\n",
    "            elif self.type == \"davisgoadrich\":\n",
    "                auroc = pkg.pr_curve(scores, weights_class0=labels, dg_compute=True)\n",
    "                auroc = auroc[2][0]\n",
    "            else:\n",
    "                raise Exception()\n",
    "            return auroc\n",
    "\n",
    "class PRROC_ROCAUC(PRROCScorer):\n",
    "    def score(self, y_score: List[float], y_real: List[int]) -> float:\n",
    "        from rpy2.rinterface_lib import openrlib\n",
    "        with openrlib.rlock:\n",
    "            pkg = import_PRROC()\n",
    "            from rpy2.robjects.vectors import FloatVector\n",
    "            labels = FloatVector(y_real)\n",
    "            scores = FloatVector(y_score)\n",
    "            auroc = pkg.roc_curve(scores, weights_class0=labels)\n",
    "            auroc = auroc[1][0]\n",
    "            return auroc\n",
    "\n",
    "@dataclass\n",
    "class ScorerInfo:\n",
    "    name: str\n",
    "    alias: str = \"\"\n",
    "    params: dict = field(default_factory=dict)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, dt: dict):\n",
    "        return cls(**dt)\n",
    "\n",
    "    def __attrs_post_init__(self):\n",
    "        if not self.alias:\n",
    "            self.alias = self.name\n",
    "    \n",
    "    def make(self):\n",
    "        if self.name == \"scikit_rocauc\":\n",
    "            return SklearnROCAUC(self.alias)\n",
    "        elif self.name == \"scikit_prauc\":\n",
    "            return SklearnPRAUC(self.alias)\n",
    "        elif self.name == \"prroc_rocauc\":\n",
    "            return PRROC_ROCAUC(self.alias)\n",
    "        elif self.name == \"prroc_prauc\":\n",
    "            tp = self.params.get(\"type\")\n",
    "            if tp is None:\n",
    "                raise Exception(\"type must be specified for prauc scorer from PRROC package\")\n",
    "            tp = tp.lower()\n",
    "            return PRROC_PRAUC(self.alias, tp)\n",
    "        elif self.name == \"constant_scorer\":\n",
    "            cons = self.params.get(\"cons\")\n",
    "            if cons is None:\n",
    "                raise Exception(\"cons must be specified for constant scorer\")\n",
    "            cons = float(cons)\n",
    "            return ConstantScorer(self.alias, cons)\n",
    "        raise Exception(f\"Wrong scorer: {self.name}\")\n",
    "    \n",
    "    def to_dict(self) -> dict:\n",
    "        dt = {}\n",
    "        dt['name'] = self.name\n",
    "        dt['alias'] = self.alias\n",
    "        dt['params'] = self.params\n",
    "        return dt\n",
    "    \n",
    "import scorer_module\n",
    "\n",
    "\n",
    "score_calc_rocauc = ScorerInfo(\"prroc_rocauc\", \"rocauc\").make()\n",
    "\n",
    "score_calc_prauc = ScorerInfo(\"prroc_prauc\", \"prauc\", params={\"type\": \"integral\"}).make()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_building(X_train, X_test, Y_train, Y_test, model_name): \n",
    "\n",
    "    print(\" \")\n",
    "    print(\"Model_building is running ...\")\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "    if model_name == \"RandomForestClassifier\":\n",
    "        MODEL = RandomForestClassifier(**{'max_depth': 6, 'max_features': 4, 'min_samples_leaf': 4, 'min_samples_split': 11, 'n_estimators': 100}, n_jobs=n_jobs)\n",
    "\n",
    "    MODEL.fit(X_train, Y_train)\n",
    "    \n",
    "    return MODEL\n",
    "\n",
    "# H - training set data type\n",
    "# M - testing set data type\n",
    "\n",
    "def rocauc_plotting(X_train_H, X_test_H, Y_train_H, Y_test_H,\n",
    "                    X_test_M, Y_test_M,\n",
    "                    Y_train_predicted_proba_H,\n",
    "                    Y_test_predicted_proba_H,\n",
    "                    Y_test_predicted_proba_M, \n",
    "                    training_obj, testing_obj, \n",
    "                    features_c, \n",
    "                    model_name, \n",
    "                    TF, plot_slim, MODEL, mtrx_di=0, mtrx_mono=0):\n",
    "\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"ROC_AUC_plotting is running ...\")\n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    fig.set_size_inches(16, 10)\n",
    "    linewidth = 5\n",
    "    color_palette = sns.color_palette(\"tab10\")\n",
    "  \n",
    "    f_c_tr_h = 0\n",
    "    best_pwm_q_list = []\n",
    "    best_pwm_number_list = []\n",
    "    for k in range(len(X_train_H.columns)):\n",
    "        f = X_train_H.columns[k]\n",
    "        fpr_train_H_PWM, tpr_train_H_PWM, thresholds = roc_curve(Y_train_H, X_train_H[f])\n",
    "        best_pwm_q_list.append(score_calc_rocauc.score(X_train_H[f], Y_train_H))\n",
    "        best_pwm_number_list.append(k)\n",
    "        \n",
    "    best_pwm_q_list_1, best_pwm_number_list1 = zip(*sorted(zip(best_pwm_q_list, best_pwm_number_list), reverse=True))\n",
    "    f_c_tr_h = best_pwm_number_list1[0]\n",
    "    \n",
    "\n",
    "    f_c_tr_h_pr = 0\n",
    "    best_pwm_q_list = []\n",
    "    best_pwm_number_list = []\n",
    "    for k in range(len(X_train_H.columns)):\n",
    "        f = X_train_H.columns[k]\n",
    "        precision_test_H_m, recall_test_H_m, thresholds = precision_recall_curve(Y_train_H, X_train_H[f])\n",
    "        best_pwm_q_list.append(score_calc_prauc.score(X_train_H[f], Y_train_H))\n",
    "        best_pwm_number_list.append(k)\n",
    "        \n",
    "    best_pwm_q_list_2, best_pwm_number_list2 = zip(*sorted(zip(best_pwm_q_list, best_pwm_number_list), reverse=True))\n",
    "    f_c_tr_h_pr = best_pwm_number_list2[0]\n",
    "    \n",
    "    \n",
    "    best_pwm_q_list = []\n",
    "    best_pwm_number_list = []\n",
    "    for k in range(len(X_train_H.columns)):\n",
    "        f = X_train_H.columns[k]\n",
    "        fpr_train_H_PWM, tpr_train_H_PWM, thresholds = roc_curve(Y_test_M, X_test_M[f])\n",
    "        best_pwm_q_list.append(score_calc_rocauc.score(X_test_M[f], Y_test_M))\n",
    "        best_pwm_number_list.append(k)\n",
    "        \n",
    "    best_pwm_q_list_3, best_pwm_number_list3 = zip(*sorted(zip(best_pwm_q_list, best_pwm_number_list), reverse=True))\n",
    "    \n",
    "    fpr_train_H_PWM, tpr_train_H_PWM, thresholds = roc_curve(Y_train_H, X_train_H[X_train_H.columns[f_c_tr_h]])\n",
    "    roc_auc_train_H_PWM_mono = score_calc_rocauc.score(X_train_H[X_train_H.columns[f_c_tr_h]], Y_train_H)\n",
    "    plt.plot(fpr_train_H_PWM, tpr_train_H_PWM, linewidth=linewidth, label=f'Train PWM {training_obj} ROC (by roc) (AUC = %0.3f)' % roc_auc_train_H_PWM_mono, color=color_palette[0])\n",
    "\n",
    "    \n",
    "    fpr_test_H_PWM, tpr_test_H_PWM, thresholds = roc_curve(Y_test_H, X_test_H[X_test_H.columns[f_c_tr_h]])\n",
    "    roc_auc_test_H_PWM_mono = score_calc_rocauc.score(X_test_H[X_test_H.columns[f_c_tr_h]], Y_test_H)\n",
    "    plt.plot(fpr_test_H_PWM, tpr_test_H_PWM, linewidth=linewidth,label=f'Test PWM {training_obj} ROC (AUC = %0.3f)' % roc_auc_test_H_PWM_mono, color=color_palette[1])\n",
    "\n",
    "    fpr_test_M_PWM, tpr_test_M_PWM, thresholds = roc_curve(Y_test_M, X_test_M[X_test_M.columns[f_c_tr_h]])\n",
    "    roc_auc_test_M_PWM_mono = score_calc_rocauc.score(X_test_M[X_test_M.columns[f_c_tr_h]], Y_test_M)\n",
    "    plt.plot(fpr_test_M_PWM, tpr_test_M_PWM, linewidth=linewidth,label=f'Test PWM {testing_obj} ROC (AUC = %0.3f)' % roc_auc_test_M_PWM_mono, color=color_palette[2])\n",
    "\n",
    "    roc_auc_train_H_PWM_di = 0\n",
    "    roc_auc_test_H_PWM_di = 0\n",
    "    roc_auc_test_M_PWM_di = 0\n",
    " \n",
    "    \n",
    "    fpr_test_M, tpr_test_M, thresholds = roc_curve(Y_test_M, Y_test_predicted_proba_M)\n",
    "    roc_auc_test_M = score_calc_rocauc.score(Y_test_predicted_proba_M, Y_test_M)\n",
    "    plt.plot(fpr_test_M, tpr_test_M, linewidth=linewidth,label=f'Test {model_name}_{mode} {testing_obj} ROC (AUC = %0.3f)' % (roc_auc_test_M), color=color_palette[3])\n",
    "\n",
    "    DF_ROC_PLOTS = pd.DataFrame()\n",
    "    DF_ROC_PLOTS[\"fpr\"] = fpr_test_M\n",
    "    DF_ROC_PLOTS[\"tpr\"] = tpr_test_M\n",
    "    DF_ROC_PLOTS.to_csv(new_dir_name + \"/\" + TF + \"_\" + model_name + \"_\" + str(features_c) + \"_DF_ROC_PLOTS_M_mono_di_test.csv\", sep=\"\\t\", index=False) # записываю \n",
    "\n",
    "\n",
    "    fpr_train_H, tpr_train_H, thresholds = roc_curve(Y_train_H, Y_train_predicted_proba_H)\n",
    "    roc_auc_train_H = score_calc_rocauc.score(Y_train_predicted_proba_H, Y_train_H)\n",
    "    plt.plot(fpr_train_H, tpr_train_H, linewidth=linewidth,label=f'Train {model_name}_{mode} {training_obj} ROC (AUC = %0.3f)' % (roc_auc_train_H), color=color_palette[4])\n",
    "\n",
    "    DF_ROC_PLOTS = pd.DataFrame()\n",
    "    DF_ROC_PLOTS[\"fpr\"] = fpr_train_H\n",
    "    DF_ROC_PLOTS[\"tpr\"] = tpr_train_H\n",
    "    DF_ROC_PLOTS.to_csv(new_dir_name + \"/\" + TF + \"_\" + model_name + \"_\" + str(features_c) + \"_DF_ROC_PLOTS_H_mono_di_train.csv\", sep=\"\\t\", index=False) # записываю \n",
    "\n",
    "    fpr_test_H, tpr_test_H, thresholds = roc_curve(Y_test_H, Y_test_predicted_proba_H)\n",
    "    roc_auc_test_H = score_calc_rocauc.score(Y_test_predicted_proba_H, Y_test_H)\n",
    "    plt.plot(fpr_test_H, tpr_test_H, linewidth=linewidth,label=f'Test {model_name}_{mode} {training_obj} ROC (AUC = %0.3f)' % (roc_auc_test_H), color=color_palette[5])\n",
    "\n",
    "    DF_ROC_PLOTS = pd.DataFrame()\n",
    "    DF_ROC_PLOTS[\"fpr\"] = fpr_test_H\n",
    "    DF_ROC_PLOTS[\"tpr\"] = tpr_test_H\n",
    "    DF_ROC_PLOTS.to_csv(new_dir_name + \"/\" + TF + \"_\" + model_name + \"_\" + str(features_c) + \"_DF_ROC_PLOTS_H_mono_di_test.csv\", sep=\"\\t\", index=False) # записываю \n",
    "\n",
    "    sns.set_context(\"paper\", font_scale=3)\n",
    "    plt.rc('legend',fontsize=12) # using a size in points\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # ideal classifier\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate', fontsize=25)\n",
    "    plt.ylabel('True Positive Rate', fontsize=25)\n",
    "\n",
    "    \n",
    "    plt.title('{model_name} besthits. {training_obj}/{testing_obj}. {N} features'.format(model_name=model_name, N=features_c, training_obj=training_obj, testing_obj=testing_obj), fontsize=20)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('ROC_AUC_{model_name}_{mode}_Train_{training_obj}_Test_{testing_obj}_{N}_features_{mode}.pdf'.format(mode=mode,model_name=model_name, N=features_c, training_obj=training_obj, testing_obj=testing_obj), dpi=100)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"PR_plotting is running ...\")\n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    fig.set_size_inches(16, 10)\n",
    "\n",
    "    precision_train_H_PWM, recall_train_H_PWM, thresholds = precision_recall_curve(Y_train_H, X_train_H[X_train_H.columns[f_c_tr_h_pr]])\n",
    "    pr_auc_train_H_PWM_mono = score_calc_prauc.score(X_train_H[X_train_H.columns[f_c_tr_h_pr]], Y_train_H)\n",
    "    plt.plot(recall_train_H_PWM, precision_train_H_PWM, linewidth=linewidth,label=f'Train PWM {training_obj} PR (by pr) (AUC = %0.3f)' % pr_auc_train_H_PWM_mono, color=color_palette[0])\n",
    "\n",
    "    \n",
    "    precision_test_H_PWM, recall_test_H_PWM, thresholds = precision_recall_curve(Y_test_H, X_test_H[X_test_H.columns[f_c_tr_h_pr]])\n",
    "    pr_auc_test_H_PWM_mono = score_calc_prauc.score(X_test_H[X_test_H.columns[f_c_tr_h_pr]], Y_test_H)\n",
    "    plt.plot(recall_test_H_PWM, precision_test_H_PWM, linewidth=linewidth,label=f'Test PWM {training_obj} PR (AUC = %0.3f)' % pr_auc_test_H_PWM_mono, color=color_palette[1])\n",
    "\n",
    "    precision_test_M_PWM, recall_test_M_PWM, thresholds = precision_recall_curve(Y_test_M, X_test_M[X_test_M.columns[f_c_tr_h_pr]])\n",
    "    pr_auc_test_M_PWM_mono = score_calc_prauc.score(X_test_M[X_test_M.columns[f_c_tr_h_pr]], Y_test_M)\n",
    "    plt.plot(recall_test_M_PWM, precision_test_M_PWM, linewidth=linewidth,label=f'Test PWM {testing_obj} PR (AUC = %0.3f)' % pr_auc_test_M_PWM_mono, color=color_palette[2])\n",
    "\n",
    "\n",
    "    pr_auc_train_H_PWM_di = 0\n",
    "    pr_auc_test_H_PWM_di = 0\n",
    "    pr_auc_test_M_PWM_di = 0\n",
    "\n",
    "    precision_test_M, recall_test_M, thresholds = precision_recall_curve(Y_test_M, Y_test_predicted_proba_M)\n",
    "    pr_auc_test_M = score_calc_prauc.score(Y_test_predicted_proba_M, Y_test_M)\n",
    "    plt.plot(recall_test_M, precision_test_M, linewidth=linewidth,label=f'Test {testing_obj} PR (AUC = %0.3f )' % (pr_auc_test_M), color=color_palette[3])\n",
    "\n",
    "\n",
    "    DF_PR_PLOTS = pd.DataFrame()\n",
    "    DF_PR_PLOTS[\"precision\"] = precision_test_M\n",
    "    DF_PR_PLOTS[\"recall\"] = recall_test_M\n",
    "    DF_PR_PLOTS.to_csv(new_dir_name + \"/\" + TF + \"_\" + model_name + \"_\" + str(features_c) + \"_DF_PR_PLOTS_M_mono_di_test.csv\", sep=\"\\t\", index=False) # записываю \n",
    "\n",
    "    ##\n",
    "    precision_train_H, recall_train_H, thresholds = precision_recall_curve(Y_train_H, Y_train_predicted_proba_H)\n",
    "    pr_auc_train_H = score_calc_prauc.score(Y_train_predicted_proba_H, Y_train_H)\n",
    "    plt.plot(recall_train_H, precision_train_H, linewidth=linewidth,label=f'Train {training_obj} PR (AUC = %0.3f )' % (pr_auc_train_H), color=color_palette[4])\n",
    "\n",
    "    DF_PR_PLOTS = pd.DataFrame()\n",
    "    DF_PR_PLOTS[\"precision\"] = precision_train_H\n",
    "    DF_PR_PLOTS[\"recall\"] = recall_train_H\n",
    "    DF_PR_PLOTS.to_csv(new_dir_name + \"/\" + TF + \"_\" + model_name + \"_\" + str(features_c) + \"_DF_PR_PLOTS_H_mono_di_train.csv\", sep=\"\\t\", index=False) # записываю \n",
    "\n",
    "    ##\n",
    "    precision_test_H, recall_test_H, thresholds = precision_recall_curve(Y_test_H, Y_test_predicted_proba_H)\n",
    "    pr_auc_test_H = score_calc_prauc.score(Y_test_predicted_proba_H, Y_test_H)\n",
    "    plt.plot(recall_test_H, precision_test_H, linewidth=linewidth,label=f'Test {training_obj} PR (AUC = %0.3f )' % (pr_auc_test_H), color=color_palette[5])\n",
    "\n",
    "    DF_PR_PLOTS = pd.DataFrame()\n",
    "    DF_PR_PLOTS[\"precision\"] = precision_test_H\n",
    "    DF_PR_PLOTS[\"recall\"] = recall_test_H\n",
    "    DF_PR_PLOTS.to_csv(new_dir_name + \"/\" + TF + \"_\" + model_name + \"_\" + str(features_c) + \"_DF_PR_PLOTS_H_mono_di_test.csv\", sep=\"\\t\", index=False) # записываю \n",
    "\n",
    "    sns.set_context(\"paper\", font_scale=3)\n",
    "    plt.rc('legend',fontsize=12)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('Recall', fontsize=25)\n",
    "    plt.ylabel('Precision', fontsize=25)\n",
    "\n",
    "\n",
    "    plt.title('{model_name} besthits. {training_obj}/{testing_obj}. {N} features'.format(model_name=model_name, N=features_c, training_obj=training_obj, testing_obj=testing_obj), fontsize=20)\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig('PR_AUC_{model_name}_{mode}_Train_{training_obj}_Test_{testing_obj}_{N}_features_{mode}.pdf'.format(mode=mode,model_name=model_name, N=features_c, training_obj=training_obj, testing_obj=testing_obj), dpi=100)\n",
    "\n",
    "\n",
    "    line_f = f'echo {features_c} {roc_auc_train_H_PWM_mono} {roc_auc_train_H_PWM_di} {roc_auc_test_H_PWM_mono} {roc_auc_test_H_PWM_di} {roc_auc_test_M_PWM_mono} {roc_auc_test_M_PWM_di} ' \\\n",
    "                 f'{roc_auc_train_H} 0 0 0 ' \\\n",
    "                 f'{roc_auc_test_H} 0 0 0 ' \\\n",
    "                 f'{roc_auc_test_M} 0 0 0 ' \\\n",
    "                 f'{pr_auc_train_H} 0 0 0 ' \\\n",
    "                 f'{pr_auc_test_H} 0 0 0 ' \\\n",
    "                 f'{pr_auc_test_M} 0 0 0 ' \\\n",
    "                 f'{pr_auc_train_H_PWM_mono} {pr_auc_train_H_PWM_di} {pr_auc_test_H_PWM_mono} {pr_auc_test_H_PWM_di} {pr_auc_test_M_PWM_mono} {pr_auc_test_M_PWM_di} ' \\\n",
    "             f' >> {TF}_new_log_roc_pr_{mode}_{today_date}.txt' # dinucleotide matrices get 0, as they are not used\n",
    "    \n",
    "    p = subprocess.Popen(line_f, shell=True)\n",
    "    p.wait()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def Scale_transform(X, scale_data):\n",
    "    if scale_data == True:\n",
    "        X_out = X.copy()\n",
    "        scaler = StandardScaler()\n",
    "        scaler_fit = scaler.fit(X_out)\n",
    "\n",
    "        print(\"mean\", scaler_fit.mean_)\n",
    "        print(\"var\", scaler_fit.var_)\n",
    "        \n",
    "        \n",
    "        X_out = pd.DataFrame(scaler_fit.transform(X_out), columns = X_out.columns)\n",
    "        X = []\n",
    "        return X_out\n",
    "    else:\n",
    "        X_out = X.copy()\n",
    "        X = []\n",
    "        return X_out\n",
    "\n",
    "    \n",
    "def scrambled(orig):\n",
    "    dest = orig[:]\n",
    "    shuffle(dest)\n",
    "    return dest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_all_scanning_res(TF, exp, dataset, flag, root, mode, model_name, pwm_scanning_res_list):\n",
    "    pwmdir = f\"{exp}/{dataset}/{TF}/pwm_scanning_results_addshift\"\n",
    "    pwm_scanning_res_list_flaged = [x + f\"_{flag}_cut.tab\" for x in pwm_scanning_res_list]\n",
    "\n",
    "    df_collector = []\n",
    "    for file_name in pwm_scanning_res_list_flaged:\n",
    "        dftmp = pd.read_csv(f\"{root}/{pwmdir}/{file_name}\", header=None, sep='\\t')[0]\n",
    "        df_collector.append(dftmp)\n",
    "    \n",
    "    df = pd.DataFrame({i:j for i,j in enumerate(df_collector)})\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def collect_all_scanning_res_CHS_scanning_with_GHTS_pwm(TF, exp, dataset, flag, root, mode, model_name, pwm_scanning_res_list):\n",
    "    pwmdir = f\"{exp}/{dataset}/{TF}/pwm_scanning_results_CHS_scanning_with_GHTS_pwm_addshift\"\n",
    "    pwm_scanning_res_list_flaged = [x + f\"_{flag}_cut.tab\" for x in pwm_scanning_res_list]\n",
    "\n",
    "    df_collector = []\n",
    "    for file_name in pwm_scanning_res_list_flaged:\n",
    "        dftmp = pd.read_csv(f\"{root}/{pwmdir}/{file_name}\", header=None, sep='\\t')[0]\n",
    "        df_collector.append(dftmp)\n",
    "    \n",
    "    df = pd.DataFrame({i:j for i,j in enumerate(df_collector)})\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def collect_all_scanning_res_GHTS_scanning_with_CHS_pwm(TF, exp, dataset, flag, root, mode, model_name, pwm_scanning_res_list):\n",
    "    pwmdir = f\"{exp}/{dataset}/{TF}/pwm_scanning_results_GHTS_scanning_with_CHS_pwm_addshift\"\n",
    "\n",
    "    pwm_scanning_res_list_flaged = [x + f\"_{flag}_cut.tab\" for x in pwm_scanning_res_list]\n",
    "    \n",
    "    df_collector = []\n",
    "    for file_name in pwm_scanning_res_list_flaged:\n",
    "        dftmp = pd.read_csv(f\"{root}/{pwmdir}/{file_name}\", header=None, sep='\\t')[0]\n",
    "        df_collector.append(dftmp)\n",
    "    \n",
    "    df = pd.DataFrame({i:j for i,j in enumerate(df_collector)})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on GHTS. Testing on CHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "FOSL2 # 0 of 139\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './input_data/best_20_motif_CHS_GHTS/GHTS/FOSL2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m TF_сalc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     31\u001b[0m pwmdir_mono \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./input_data/best_20_motif_CHS_GHTS/GHTS\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 32\u001b[0m dir_list \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpwmdir_mono\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTF\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     33\u001b[0m pwm_scanning_res_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m exp_pwm_dir \u001b[38;5;129;01min\u001b[39;00m dir_list:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './input_data/best_20_motif_CHS_GHTS/GHTS/FOSL2'"
     ]
    }
   ],
   "source": [
    "organism = \"HUMAN_GHTS_CHS\" # GHTS to CHS\n",
    "n_jobs = 8\n",
    "scale_data = True\n",
    "print_GC = False\n",
    "verbose = True\n",
    "\n",
    "today = date.today()\n",
    "today_date = today.strftime(\"%d.%m.%Y\")    \n",
    "\n",
    "mode  = \"mono\" # which PWMs to use. Mono nucleotide by default \n",
    "model_name  = \"RandomForestClassifier\"\n",
    "sys.setrecursionlimit = 10**3 \n",
    "\n",
    "\n",
    "model_dir = os.path.abspath('train_on_GHTS_predict_on_CHS') \n",
    "basicdir = model_dir\n",
    "new_dir_name = model_dir\n",
    "\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "os.chdir(model_dir)\n",
    "\n",
    "\n",
    "TF_сalc = 0\n",
    "for TF in [\"FOSL2\"]: #TFs_CHS_AFS: # For DEMO tests use [\"GABPA\"] instead of TFs_CHS_AFS. \n",
    "    print(\" \")\n",
    "    print(f\"{TF} #\" + \" {сalc} of {all_c}\".format(all_c=len(TFs_CHS_AFS), сalc=TF_сalc))\n",
    "    TF_сalc += 1\n",
    "\n",
    "    pwmdir_mono = \"./input_data/best_20_motif_CHS_GHTS/GHTS\"\n",
    "    dir_list = os.listdir(pwmdir_mono + \"/\" + TF) \n",
    "    pwm_scanning_res_list = []\n",
    "\n",
    "    for exp_pwm_dir in dir_list:\n",
    "        pwm_local_dir = pwmdir_mono + \"/\" + TF + \"/\" + exp_pwm_dir\n",
    "        pwm_local_list = [x.split(\".pwm\")[0] for x in os.listdir(pwm_local_dir) if \"pwm\" in x]\n",
    "        pwm_scanning_res_list.extend(pwm_local_list)\n",
    "\n",
    "\n",
    "    pwm_scanning_res_list = list(set(pwm_scanning_res_list))\n",
    "\n",
    "    df_pos = collect_all_scanning_res(TF, \"GHTS\", \"Train\", \"positives\", root, mode, model_name, pwm_scanning_res_list)\n",
    "    df_neg = collect_all_scanning_res(TF, \"GHTS\", \"Train\", \"random\", root, mode, model_name, pwm_scanning_res_list)\n",
    "\n",
    "    df_pos[\"ind\"] = 1\n",
    "    df_neg[\"ind\"] = 0\n",
    "    df = pd.concat([df_pos, df_neg])\n",
    "    \n",
    "    X_train_GHTS, Y_train_GHTS = df.iloc[:,:-1], df[\"ind\"]\n",
    "    \n",
    "    X_out = X_train_GHTS.copy()\n",
    "    scaler = StandardScaler()\n",
    "    scaler_fit = scaler.fit(X_out)\n",
    "    \n",
    "    X_train_GHTS = pd.DataFrame(scaler_fit.transform(X_train_GHTS), columns = X_train_GHTS.columns)\n",
    "    \n",
    "    df_pos = collect_all_scanning_res(TF, \"GHTS\", \"Test\", \"positives\", root, mode, model_name, pwm_scanning_res_list)\n",
    "    df_neg = collect_all_scanning_res(TF, \"GHTS\", \"Test\", \"random\", root, mode, model_name, pwm_scanning_res_list)\n",
    "    \n",
    "    df_pos[\"ind\"] = 1\n",
    "    df_neg[\"ind\"] = 0\n",
    "    df = pd.concat([df_pos, df_neg])\n",
    "    \n",
    "    X_test_GHTS, Y_test_GHTS = df.iloc[:,:-1], df[\"ind\"]\n",
    "    X_test_GHTS = pd.DataFrame(scaler_fit.transform(X_test_GHTS), columns = X_test_GHTS.columns)\n",
    "    \n",
    "    df_pos = collect_all_scanning_res_CHS_scanning_with_GHTS_pwm(TF, \"CHS\", \"Test\", \"positives\", root, mode, model_name, pwm_scanning_res_list)\n",
    "    df_neg = collect_all_scanning_res_CHS_scanning_with_GHTS_pwm(TF, \"CHS\", \"Test\", \"random\", root, mode, model_name, pwm_scanning_res_list)\n",
    "    \n",
    "    df_pos[\"ind\"] = 1\n",
    "    df_neg[\"ind\"] = 0\n",
    "    df = pd.concat([df_pos, df_neg])\n",
    "    \n",
    "    X_test_CHS, Y_test_CHS = df.iloc[:,:-1], df[\"ind\"]\n",
    "    X_test_CHS = pd.DataFrame(scaler_fit.transform(X_test_CHS), columns = X_test_CHS.columns)\n",
    "    \n",
    "    #MODEL = model_building(X_train_GHTS, X_test_GHTS, Y_train_GHTS, Y_test_GHTS, model_name)\n",
    "    \n",
    "    filename = f\"./pre_trained_ArChIPelago_models/GHTS_to_CHS_models/{TF}_model.sav\"\n",
    "    MODEL = pickle.load(open(filename, 'rb')) # requires scikit-learn==1.3.0\n",
    "\n",
    "    # extracting feature_importances\n",
    "    \n",
    "    importances = MODEL.feature_importances_\n",
    "    feature_names = pwm_scanning_res_list\n",
    "    forest_importances = pd.Series(importances, index=feature_names)\n",
    "    print(forest_importances)\n",
    "    forest_importances_sorted = forest_importances.sort_values(ascending=False) \n",
    "    print(forest_importances_sorted)\n",
    "\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on CHS. Testing on GHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organism = \"HUMAN_CHS_GHTS\" # CHS to GHTS\n",
    "n_jobs = 100\n",
    "scale_data = True\n",
    "print_GC = False\n",
    "verbose = True\n",
    "\n",
    "# today = date.today()\n",
    "# today_date = today.strftime(\"%d.%m.%Y\")    \n",
    "\n",
    "mode  = \"mono\" # which PWMs to use. Mono nucleotide by default \n",
    "model_name  = \"RandomForestClassifier\"\n",
    "sys.setrecursionlimit = 10**3 \n",
    "\n",
    "\n",
    "model_dir = os.path.abspath('train_on_CHS_predict_on_GHTS') \n",
    "basicdir = model_dir\n",
    "new_dir_name = model_dir\n",
    "\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "os.chdir(model_dir)\n",
    "\n",
    "\n",
    "TF_сalc = 0\n",
    "for TF in TFs_CHS_AFS:   # For DEMO tests use [\"GABPA\"] instead of TFs_CHS_AFS. \n",
    "    print(\" \")\n",
    "    print(f\"{TF} #\" + \" {сalc} of {all_c}\".format(all_c=len(TFs_CHS_AFS), сalc=TF_сalc))\n",
    "    TF_сalc += 1\n",
    "\n",
    "    pwmdir_mono = \"/home/ivankozin/projects/best_20_motif_CHS_GHTS/CHS\"\n",
    "    dir_list = os.listdir(pwmdir_mono + \"/\" + TF) \n",
    "    pwm_scanning_res_list = []\n",
    "\n",
    "    for exp_pwm_dir in dir_list:\n",
    "        pwm_local_dir = pwmdir_mono + \"/\" + TF + \"/\" + exp_pwm_dir\n",
    "        pwm_local_list = [x.split(\".pwm\")[0] for x in os.listdir(pwm_local_dir) if \"pwm\" in x]\n",
    "        pwm_scanning_res_list.extend(pwm_local_list)\n",
    "\n",
    "\n",
    "    pwm_scanning_res_list = list(set(pwm_scanning_res_list))\n",
    "\n",
    "    df_pos = collect_all_scanning_res(TF, \"CHS\", \"Train\", \"positives\", root, mode, model_name, pwm_scanning_res_list)\n",
    "    df_neg = collect_all_scanning_res(TF, \"CHS\", \"Train\", \"random\", root, mode, model_name, pwm_scanning_res_list)\n",
    "\n",
    "    df_pos[\"ind\"] = 1\n",
    "    df_neg[\"ind\"] = 0\n",
    "    df = pd.concat([df_pos, df_neg])\n",
    "    \n",
    "    X_train_GHTS, Y_train_GHTS = df.iloc[:,:-1], df[\"ind\"]\n",
    "    \n",
    "    X_out = X_train_GHTS.copy()\n",
    "    scaler = StandardScaler()\n",
    "    scaler_fit = scaler.fit(X_out)\n",
    "    \n",
    "    X_train_GHTS = pd.DataFrame(scaler_fit.transform(X_train_GHTS), columns = X_train_GHTS.columns)\n",
    "    \n",
    "    df_pos = collect_all_scanning_res(TF, \"CHS\", \"Test\", \"positives\", root, mode, model_name, pwm_scanning_res_list)\n",
    "    df_neg = collect_all_scanning_res(TF, \"CHS\", \"Test\", \"random\", root, mode, model_name, pwm_scanning_res_list)\n",
    "    \n",
    "    df_pos[\"ind\"] = 1\n",
    "    df_neg[\"ind\"] = 0\n",
    "    df = pd.concat([df_pos, df_neg])\n",
    "    \n",
    "    X_test_GHTS, Y_test_GHTS = df.iloc[:,:-1], df[\"ind\"]\n",
    "    X_test_GHTS = pd.DataFrame(scaler_fit.transform(X_test_GHTS), columns = X_test_GHTS.columns)\n",
    "    \n",
    "    df_pos = collect_all_scanning_res_GHTS_scanning_with_CHS_pwm(TF, \"GHTS\", \"Test\", \"positives\", root, mode, model_name, pwm_scanning_res_list)\n",
    "    df_neg = collect_all_scanning_res_GHTS_scanning_with_CHS_pwm(TF, \"GHTS\", \"Test\", \"random\", root, mode, model_name, pwm_scanning_res_list)\n",
    "    \n",
    "    df_pos[\"ind\"] = 1\n",
    "    df_neg[\"ind\"] = 0\n",
    "    df = pd.concat([df_pos, df_neg])\n",
    "    \n",
    "    X_test_CHS, Y_test_CHS = df.iloc[:,:-1], df[\"ind\"]\n",
    "    X_test_CHS = pd.DataFrame(scaler_fit.transform(X_test_CHS), columns = X_test_CHS.columns)\n",
    "    \n",
    "    #MODEL = model_building(X_train_GHTS, X_test_GHTS, Y_train_GHTS, Y_test_GHTS, model_name)\n",
    "    \n",
    "    filename = f\"./pre_trained_ArChIPelago_models/CHS_to_GHTS_models/{TF}_model.sav\"\n",
    "    MODEL = pickle.load(open(filename, 'rb')) # requires scikit-learn==1.3.0\n",
    "\n",
    "    importances = MODEL.feature_importances_\n",
    "    feature_names = pwm_scanning_res_list\n",
    "    forest_importances = pd.Series(importances, index=feature_names)\n",
    "    print(forest_importances)\n",
    "    forest_importances_sorted = forest_importances.sort_values(ascending=False) \n",
    "    print(forest_importances_sorted)\n",
    "    \n",
    "    \n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
