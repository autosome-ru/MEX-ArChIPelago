{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import argparse\n",
    "import subprocess\n",
    "import matplotlib\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import shlex\n",
    "import shutil\n",
    "import glob\n",
    "import pickle\n",
    "import csv\n",
    "import operator\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from collections import defaultdict\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from Bio import SeqIO\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import preprocessing\n",
    "import pybedtools as pbt\n",
    "import pyBigWig as pbw\n",
    "from datetime import date\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import chain\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from adjustText import adjust_text\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFs_CHS_AFS = pd.read_csv(\"./Input_data/best_20_motif_CHS_GHTS.txt\", sep=\"\\t\", header=None)\n",
    "TFs_CHS_AFS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "! wget https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz; gunzip hg38.fa.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta = pbt.example_filename('./hg38.fa') # please download the reference file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./pbt_exclusion_zone\"): # create a directory for pybedtools tmp files\n",
    "    os.makedirs(\"./pbt_exclusion_zone\")\n",
    "pbt.helpers.set_tempdir(\"./pbt_exclusion_zone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing GHTS (AFS) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"[your path to dir]/MEX-ArChIPelago/\" \n",
    "basicdir = os.path.abspath('GHTS/')\n",
    "outputdir = os.path.abspath('GHTS/outputdir')\n",
    "train_dir = os.path.abspath('GHTS/Train/') \n",
    "test_dir = os.path.abspath('GHTS/Test/') \n",
    "\n",
    "if not os.path.exists(basicdir): \n",
    "    os.makedirs(basicdir)\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [x for x in os.listdir(\"./Input_data/GHTS/Test/\") if x in list(TFs_CHS_AFS[0])]:\n",
    "    print(test_dir+\"/\"+i)\n",
    "    if not os.path.exists(test_dir+\"/\"+i):\n",
    "        os.makedirs(test_dir+\"/\"+i)\n",
    "    for j in os.listdir(\"./Input_data/GHTS/Test/\"+i):\n",
    "        dfm = pd.read_csv(f\"./Input_data/GHTS/Test/{i}/foreigns.bed\", sep=\"\\t\", header=None)\n",
    "        foreigns = pbt.BedTool.from_dataframe(dfm)\n",
    "        foreigns = foreigns.sequence(fi=fasta)\n",
    "        foreigns_fa = open(foreigns.seqfn).read()\n",
    "        with open(test_dir+\"/\"+i+\"/foreigns.fa\", \"w\") as f:\n",
    "            f.write(foreigns_fa)\n",
    "            \n",
    "        dfm = pd.read_csv(f\"./Input_data/GHTS/Test/{i}/positives.bed\", sep=\"\\t\", header=None)\n",
    "        positives = pbt.BedTool.from_dataframe(dfm)\n",
    "        positives = positives.sequence(fi=fasta)\n",
    "        positives_fa = open(positives.seqfn).read()\n",
    "        with open(test_dir+\"/\"+i+\"/positives.fa\", \"w\") as f:\n",
    "            f.write(positives_fa)\n",
    "        \n",
    "        dfm = pd.read_csv(f\"./Input_data/GHTS/Test/{i}/random.bed\", sep=\"\\t\", header=None)\n",
    "        random = pbt.BedTool.from_dataframe(dfm)\n",
    "        random = random.sequence(fi=fasta)\n",
    "        random_fa = open(random.seqfn).read()\n",
    "        with open(test_dir+\"/\"+i+\"/random.fa\", \"w\") as f:\n",
    "            f.write(random_fa)\n",
    "        \n",
    "        dfm = pd.read_csv(f\"./Input_data/GHTS/Test/{i}/shades.bed\", sep=\"\\t\", header=None)\n",
    "        shades = pbt.BedTool.from_dataframe(dfm)\n",
    "        shades = shades.sequence(fi=fasta)\n",
    "        shades_fa = open(shades.seqfn).read()\n",
    "        with open(test_dir+\"/\"+i+\"/shades.fa\", \"w\") as f:\n",
    "            f.write(shades_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [x for x in os.listdir(\"./Input_data/GHTS/Train/\") if x in list(TFs_CHS_AFS[0])]:\n",
    "    print(train_dir+\"/\"+i)\n",
    "    if not os.path.exists(train_dir+\"/\"+i):\n",
    "        os.makedirs(train_dir+\"/\"+i)\n",
    "    for j in os.listdir(\"./Input_data/GHTS/Train/\"+i):\n",
    "        dfm = pd.read_csv(f\"./Input_data/GHTS/Train/{i}/foreigns.bed\", sep=\"\\t\", header=None)\n",
    "        foreigns = pbt.BedTool.from_dataframe(dfm)\n",
    "        foreigns = foreigns.sequence(fi=fasta)\n",
    "        foreigns_fa = open(foreigns.seqfn).read()\n",
    "        with open(train_dir+\"/\"+i+\"/foreigns.fa\", \"w\") as f:\n",
    "            f.write(foreigns_fa)\n",
    "            \n",
    "        dfm = pd.read_csv(f\"./Input_data/GHTS/Train/{i}/positives.bed\", sep=\"\\t\", header=None)\n",
    "        positives = pbt.BedTool.from_dataframe(dfm)\n",
    "        positives = positives.sequence(fi=fasta)\n",
    "        positives_fa = open(positives.seqfn).read()\n",
    "        with open(train_dir+\"/\"+i+\"/positives.fa\", \"w\") as f:\n",
    "            f.write(positives_fa)\n",
    "        \n",
    "        dfm = pd.read_csv(f\"./Input_data/GHTS/Train/{i}/random_addshift.bed\", sep=\"\\t\", header=None)\n",
    "        random = pbt.BedTool.from_dataframe(dfm)\n",
    "        random = random.sequence(fi=fasta)\n",
    "        random_fa = open(random.seqfn).read()\n",
    "        with open(train_dir+\"/\"+i+\"/random.fa\", \"w\") as f:\n",
    "            f.write(random_fa)\n",
    "        \n",
    "        dfm = pd.read_csv(f\"./Input_data/GHTS/Train/{i}/shades_addshift.bed\", sep=\"\\t\", header=None)\n",
    "        shades = pbt.BedTool.from_dataframe(dfm)\n",
    "        shades = shades.sequence(fi=fasta)\n",
    "        shades_fa = open(shades.seqfn).read()\n",
    "        with open(train_dir+\"/\"+i+\"/shades.fa\", \"w\") as f:\n",
    "            f.write(shades_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [x for x in os.listdir(\"./Input_data/GHTS/Test/\") if x in list(TFs_CHS_AFS[0])]:\n",
    "    print(test_dir+\"/\"+i)\n",
    "    if not os.path.exists(test_dir+\"/\"+i):\n",
    "        os.makedirs(test_dir+\"/\"+i)\n",
    "    for j in os.listdir(\"./Input_data/GHTS/Test/\"+i):\n",
    "        line = f\"awk 'NF' {test_dir}/{i}/positives.fa > {test_dir}/{i}/positives_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()\n",
    "        line = f\"awk 'NF' {test_dir}/{i}/foreigns.fa > {test_dir}/{i}/foreigns_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()\n",
    "        \n",
    "        line = f\"awk 'NF' {test_dir}/{i}/random.fa > {test_dir}/{i}/random_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()\n",
    "\n",
    "        line = f\"awk 'NF' {test_dir}/{i}/shades.fa > {test_dir}/{i}/shades_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [x for x in os.listdir(\"./Input_data/GHTS/Train/\") if x in list(TFs_CHS_AFS[0])]:\n",
    "    print(train_dir+\"/\"+i)\n",
    "    if not os.path.exists(train_dir+\"/\"+i):\n",
    "        os.makedirs(train_dir+\"/\"+i)\n",
    "    for j in os.listdir(\"./Input_data/GHTS/Train/\"+i):\n",
    "        line = f\"awk 'NF' {train_dir}/{i}/positives.fa > {train_dir}/{i}/positives_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()\n",
    "        line = f\"awk 'NF' {train_dir}/{i}/foreigns.fa > {train_dir}/{i}/foreigns_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()\n",
    "        \n",
    "        line = f\"awk 'NF' {train_dir}/{i}/random.fa > {train_dir}/{i}/random_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()\n",
    "\n",
    "        line = f\"awk 'NF' {train_dir}/{i}/shades.fa > {train_dir}/{i}/shades_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing CHS data¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basicdir = os.path.abspath('CHS/')\n",
    "outputdir = os.path.abspath('CHS/outputdir')\n",
    "train_dir = os.path.abspath('CHS/Train/') \n",
    "test_dir = os.path.abspath('CHS/Test/') \n",
    "\n",
    "if not os.path.exists(basicdir): \n",
    "    os.makedirs(basicdir)\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [x for x in os.listdir(\"./Input_data/CHS/Test/\") if x in list(TFs_CHS_AFS[0])]:\n",
    "    print(test_dir+\"/\"+i)\n",
    "    if not os.path.exists(test_dir+\"/\"+i):\n",
    "        os.makedirs(test_dir+\"/\"+i)\n",
    "    for j in os.listdir(\"./Input_data/CHS/Test/\"+i):\n",
    "        dfm = pd.read_csv(f\"./Input_data/CHS/Test/{i}/foreigns.bed\", sep=\"\\t\", header=None)\n",
    "        foreigns = pbt.BedTool.from_dataframe(dfm)\n",
    "        foreigns = foreigns.sequence(fi=fasta)\n",
    "        foreigns_fa = open(foreigns.seqfn).read()\n",
    "        with open(test_dir+\"/\"+i+\"/foreigns.fa\", \"w\") as f:\n",
    "            f.write(foreigns_fa)\n",
    "            \n",
    "        dfm = pd.read_csv(f\"./Input_data/CHS/Test/{i}/positives.bed\", sep=\"\\t\", header=None)\n",
    "        positives = pbt.BedTool.from_dataframe(dfm)\n",
    "        positives = positives.sequence(fi=fasta)\n",
    "        positives_fa = open(positives.seqfn).read()\n",
    "        with open(test_dir+\"/\"+i+\"/positives.fa\", \"w\") as f:\n",
    "            f.write(positives_fa)\n",
    "        \n",
    "        dfm = pd.read_csv(f\"./Input_data/CHS/Test/{i}/random.bed\", sep=\"\\t\", header=None)\n",
    "        random = pbt.BedTool.from_dataframe(dfm)\n",
    "        random = random.sequence(fi=fasta)\n",
    "        random_fa = open(random.seqfn).read()\n",
    "        with open(test_dir+\"/\"+i+\"/random.fa\", \"w\") as f:\n",
    "            f.write(random_fa)\n",
    "        \n",
    "        dfm = pd.read_csv(f\"./Input_data/CHS/Test/{i}/shades.bed\", sep=\"\\t\", header=None)\n",
    "        shades = pbt.BedTool.from_dataframe(dfm)\n",
    "        shades = shades.sequence(fi=fasta)\n",
    "        shades_fa = open(shades.seqfn).read()\n",
    "        with open(test_dir+\"/\"+i+\"/shades.fa\", \"w\") as f:\n",
    "            f.write(shades_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [x for x in os.listdir(\"./Input_data/CHS/Train/\") if x in list(TFs_CHS_AFS[0])]:\n",
    "    print(train_dir+\"/\"+i)\n",
    "    if not os.path.exists(train_dir+\"/\"+i):\n",
    "        os.makedirs(train_dir+\"/\"+i)\n",
    "    for j in os.listdir(\"./Input_data/CHS/Train/\"+i):\n",
    "        dfm = pd.read_csv(f\"./Input_data/CHS/Train/{i}/foreigns.bed\", sep=\"\\t\", header=None)\n",
    "        foreigns = pbt.BedTool.from_dataframe(dfm)\n",
    "        foreigns = foreigns.sequence(fi=fasta)\n",
    "        foreigns_fa = open(foreigns.seqfn).read()\n",
    "        with open(train_dir+\"/\"+i+\"/foreigns.fa\", \"w\") as f:\n",
    "            f.write(foreigns_fa)\n",
    "            \n",
    "        dfm = pd.read_csv(f\"./Input_data/CHS/Train/{i}/positives.bed\", sep=\"\\t\", header=None)\n",
    "        positives = pbt.BedTool.from_dataframe(dfm)\n",
    "        positives = positives.sequence(fi=fasta)\n",
    "        positives_fa = open(positives.seqfn).read()\n",
    "        with open(train_dir+\"/\"+i+\"/positives.fa\", \"w\") as f:\n",
    "            f.write(positives_fa)\n",
    "        \n",
    "        dfm = pd.read_csv(f\"./Input_data/CHS/Train/{i}/random_addshift.bed\", sep=\"\\t\", header=None)\n",
    "        random = pbt.BedTool.from_dataframe(dfm)\n",
    "        random = random.sequence(fi=fasta)\n",
    "        random_fa = open(random.seqfn).read()\n",
    "        with open(train_dir+\"/\"+i+\"/random.fa\", \"w\") as f:\n",
    "            f.write(random_fa)\n",
    "        \n",
    "        dfm = pd.read_csv(f\"./Input_data/CHS/Train/{i}/shades_addshift.bed\", sep=\"\\t\", header=None)\n",
    "        shades = pbt.BedTool.from_dataframe(dfm)\n",
    "        shades = shades.sequence(fi=fasta)\n",
    "        shades_fa = open(shades.seqfn).read()\n",
    "        with open(train_dir+\"/\"+i+\"/shades.fa\", \"w\") as f:\n",
    "            f.write(shades_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [x for x in os.listdir(\"./Input_data/CHS/Test/\") if x in list(TFs_CHS_AFS[0])]:\n",
    "    print(test_dir+\"/\"+i)\n",
    "    if not os.path.exists(test_dir+\"/\"+i):\n",
    "        os.makedirs(test_dir+\"/\"+i)\n",
    "    for j in os.listdir(\"./Input_data/CHS/Test/\"+i):\n",
    "        line = f\"awk 'NF' {test_dir}/{i}/positives.fa > {test_dir}/{i}/positives_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()\n",
    "        line = f\"awk 'NF' {test_dir}/{i}/foreigns.fa > {test_dir}/{i}/foreigns_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()\n",
    "        \n",
    "        line = f\"awk 'NF' {test_dir}/{i}/random.fa > {test_dir}/{i}/random_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()\n",
    "\n",
    "        line = f\"awk 'NF' {test_dir}/{i}/shades.fa > {test_dir}/{i}/shades_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [x for x in os.listdir(\"./Input_data/CHS/Train/\") if x in list(TFs_CHS_AFS[0])]:\n",
    "    print(train_dir+\"/\"+i)\n",
    "    if not os.path.exists(train_dir+\"/\"+i):\n",
    "        os.makedirs(train_dir+\"/\"+i)\n",
    "    for j in os.listdir(\"./Input_data/CHS/Train/\"+i):\n",
    "        line = f\"awk 'NF' {train_dir}/{i}/positives.fa > {train_dir}/{i}/positives_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()\n",
    "        line = f\"awk 'NF' {train_dir}/{i}/foreigns.fa > {train_dir}/{i}/foreigns_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()\n",
    "        \n",
    "        line = f\"awk 'NF' {train_dir}/{i}/random.fa > {train_dir}/{i}/random_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()\n",
    "\n",
    "        line = f\"awk 'NF' {train_dir}/{i}/shades.fa > {train_dir}/{i}/shades_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
