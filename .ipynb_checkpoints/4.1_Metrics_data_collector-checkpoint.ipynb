{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Collecting data for violin plots (SF5 A,B,C,D,E,F and SF6 A,B,C,D,E,F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import argparse\n",
    "import subprocess\n",
    "import matplotlib\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import shlex\n",
    "import shutil\n",
    "import glob\n",
    "import pickle\n",
    "import csv\n",
    "import operator\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from collections import defaultdict\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from Bio import SeqIO\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import preprocessing\n",
    "import pybedtools as pbt\n",
    "import pyBigWig as pbw\n",
    "from datetime import date\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import chain\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from adjustText import adjust_text\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting results for GHTS -> CHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_class = 10000\n",
    "neg_class = pos_class * 100\n",
    "N_features = 1000         \n",
    "n_jobs = 100\n",
    "plot_slim = False\n",
    "scale_data = True\n",
    "print_GC = False\n",
    "verbose = True\n",
    "organism = \"HUMAN_GHTS_CHS\"\n",
    "mode  = \"mono\"\n",
    "model_name  = \"RandomForestClassifier\"\n",
    "sys.setrecursionlimit = 10**3 # for deeper recursion\n",
    "\n",
    "\n",
    "today_date = \"...\" # please use as in #3\n",
    "\n",
    "\n",
    "root = \"[your path to dir]/MEX-ArChIPelago/\" \n",
    "os.chdir(root)\n",
    "model_dir = os.path.abspath('train_on_GHTS_predict_on_CHS')\n",
    "os.chdir(model_dir)\n",
    "\n",
    "# H - training set data type\n",
    "# M - testing set data type\n",
    "\n",
    "colnames_l = [\"Count\", \"roc_auc_train_H_PWM\", \"roc_auc_train_H_PWM_di\", \"roc_auc_test_H_PWM\", \n",
    " \"roc_auc_test_H_PWM_di\", \"roc_auc_test_M_PWM\", \"roc_auc_test_M_PWM_di\",\n",
    "\"roc_auc_train_H\", \"mean_auc_train_H\", \"median_auc_train_H\", \"std_auc_train_H\",\n",
    "\"roc_auc_test_H\", \"mean_auc_test_H\", \"median_auc_test_H\", \"std_auc_test_H\",\n",
    "\"roc_auc_test_M\", \"mean_auc_test_M\", \"median_auc_test_M\", \"std_auc_test_M\",\n",
    "\"pr_auc_train_H\", \"mean_pr_auc_train_H\", \"median_pr_auc_train_H\", \"std_pr_auc_train_H\",\n",
    "\"pr_auc_test_H\", \"mean_pr_auc_test_H\", \"median_pr_auc_test_H\", \"std_pr_auc_test_H\",\n",
    "\"pr_auc_test_M\", \"mean_pr_auc_test_M\", \"median_pr_auc_test_M\", \"std_pr_auc_test_M\",\n",
    "\"pr_auc_train_H_PWM\", \"pr_auc_train_H_PWM_di\", \"pr_auc_test_H_PWM\", \"pr_auc_test_H_PWM_di\", \n",
    "\"pr_auc_test_M_PWM\", \"pr_auc_test_M_PWM_di\"]\n",
    "\n",
    "df_l = []\n",
    "TF_сalc = 0\n",
    "for TF in files_pwm_HUMAN_mono:   \n",
    "    TF_сalc += 1\n",
    "    ddf = pd.read_csv(f\"{TF}_new_log_roc_pr_{mode}_{today_date}.txt\",  sep=' ', header=None)\n",
    "    ddf.columns = colnames_l\n",
    "    ddf[\"TF_name\"] = TF\n",
    "    ddf[\"Model\"] = model_name\n",
    "    ddf[\"PWM\"] = mode\n",
    "    df_l.append(ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat(df_l)\n",
    "df_total = df_total[(df_total[\"Model\"] == \"RandomForestClassifier\")]\n",
    "df_total[\"PR_delta_H\"] = df_total[\"pr_auc_test_H\"]-df_total[\"pr_auc_test_H_PWM\"]\n",
    "df_total[\"ROC_delta_H\"] = df_total[\"roc_auc_test_H\"]-df_total[\"roc_auc_test_H_PWM\"]\n",
    "df_total[\"PR_delta_M\"] = df_total[\"pr_auc_test_M\"]-df_total[\"pr_auc_test_M_PWM\"]\n",
    "df_total[\"ROC_delta_M\"] = df_total[\"roc_auc_test_M\"]-df_total[\"roc_auc_test_M_PWM\"]\n",
    "df_total = df_total[df_total[\"PWM\"] == \"mono\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_l = []\n",
    "lll_p = []\n",
    "lll_s = []\n",
    "lll_f = []\n",
    "lll_r = []\n",
    "\n",
    "for i in files_pwm_HUMAN_mono:\n",
    "\n",
    "    dfm = pd.read_csv(f\"./Input_data/GHTS/Test/{i}/positives.bed\", sep=\"\\t\", header=None)\n",
    "    lll_p.append(dfm.shape[0])\n",
    "    dfm = pd.read_csv(f\"./Input_data/GHTS/Test/{i}/random_addshift.bed\", sep=\"\\t\", header=None)\n",
    "    lll_r.append(dfm.shape[0])\n",
    "    dfm = pd.read_csv(f\"./Input_data/GHTS/Test/{i}/foreigns.bed\", sep=\"\\t\", header=None)\n",
    "    lll_f.append(dfm.shape[0])\n",
    "    dfm = pd.read_csv(f\"./Input_data/GHTS/Test/{i}/shades_addshift.bed\", sep=\"\\t\", header=None)\n",
    "    lll_s.append(dfm.shape[0])\n",
    "    TF_l.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = pd.DataFrame({\"TF_name\":TF_l, \"Seq_count_positives\":lll_p, \"Seq_count_random\":lll_r, \"Seq_count_alien\":lll_f, \"Seq_count_shades\":lll_s})\n",
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.merge(df_total, ddf, on='TF_name', how='left')\n",
    "df_total\n",
    "df_total = df_total.drop_duplicates()\n",
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.to_csv(\"./output/train_on_GHTS_predict_on_CHS_nodup_RF.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting results for CHS -> GHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_class = 10000\n",
    "neg_class = pos_class * 100\n",
    "N_features = 1000         \n",
    "n_jobs = 100\n",
    "plot_slim = False\n",
    "scale_data = True\n",
    "print_GC = False\n",
    "verbose = True\n",
    "organism = \"HUMAN_CHS_GHTS\"\n",
    "mode  = \"mono\"\n",
    "model_name  = \"RandomForestClassifier\"\n",
    "sys.setrecursionlimit = 10**3 # for deeper recursion\n",
    "\n",
    "\n",
    "today_date = \"...\" # please use as in #3\n",
    "\n",
    "\n",
    "root = \"[your path to dir]/MEX-ArChIPelago/\" \n",
    "os.chdir(root)\n",
    "model_dir = os.path.abspath('train_on_CHS_predict_on_GHTS')\n",
    "os.chdir(model_dir)\n",
    "\n",
    "# H - training set data type\n",
    "# M - testing set data type\n",
    "\n",
    "colnames_l = [\"Count\", \"roc_auc_train_H_PWM\", \"roc_auc_train_H_PWM_di\", \"roc_auc_test_H_PWM\", \n",
    " \"roc_auc_test_H_PWM_di\", \"roc_auc_test_M_PWM\", \"roc_auc_test_M_PWM_di\",\n",
    "\"roc_auc_train_H\", \"mean_auc_train_H\", \"median_auc_train_H\", \"std_auc_train_H\",\n",
    "\"roc_auc_test_H\", \"mean_auc_test_H\", \"median_auc_test_H\", \"std_auc_test_H\",\n",
    "\"roc_auc_test_M\", \"mean_auc_test_M\", \"median_auc_test_M\", \"std_auc_test_M\",\n",
    "\"pr_auc_train_H\", \"mean_pr_auc_train_H\", \"median_pr_auc_train_H\", \"std_pr_auc_train_H\",\n",
    "\"pr_auc_test_H\", \"mean_pr_auc_test_H\", \"median_pr_auc_test_H\", \"std_pr_auc_test_H\",\n",
    "\"pr_auc_test_M\", \"mean_pr_auc_test_M\", \"median_pr_auc_test_M\", \"std_pr_auc_test_M\",\n",
    "\"pr_auc_train_H_PWM\", \"pr_auc_train_H_PWM_di\", \"pr_auc_test_H_PWM\", \"pr_auc_test_H_PWM_di\", \n",
    "\"pr_auc_test_M_PWM\", \"pr_auc_test_M_PWM_di\"]\n",
    "\n",
    "df_l = []\n",
    "TF_сalc = 0\n",
    "for TF in files_pwm_HUMAN_mono:   \n",
    "    TF_сalc += 1\n",
    "    ddf = pd.read_csv(f\"{TF}_new_log_roc_pr_{mode}_{today_date}.txt\",  sep=' ', header=None)\n",
    "    ddf.columns = colnames_l\n",
    "    ddf[\"TF_name\"] = TF\n",
    "    ddf[\"Model\"] = model_name\n",
    "    ddf[\"PWM\"] = mode\n",
    "    df_l.append(ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat(df_l)\n",
    "df_total = df_total[(df_total[\"Model\"] == \"RandomForestClassifier\")]\n",
    "df_total[\"PR_delta_H\"] = df_total[\"pr_auc_test_H\"]-df_total[\"pr_auc_test_H_PWM\"]\n",
    "df_total[\"ROC_delta_H\"] = df_total[\"roc_auc_test_H\"]-df_total[\"roc_auc_test_H_PWM\"]\n",
    "df_total[\"PR_delta_M\"] = df_total[\"pr_auc_test_M\"]-df_total[\"pr_auc_test_M_PWM\"]\n",
    "df_total[\"ROC_delta_M\"] = df_total[\"roc_auc_test_M\"]-df_total[\"roc_auc_test_M_PWM\"]\n",
    "df_total = df_total[df_total[\"PWM\"] == \"mono\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_l = []\n",
    "lll_p = []\n",
    "lll_s = []\n",
    "lll_f = []\n",
    "lll_r = []\n",
    "\n",
    "for i in files_pwm_HUMAN_mono:\n",
    "\n",
    "    dfm = pd.read_csv(f\"./Input_data/CHS/Test/{i}/positives.bed\", sep=\"\\t\", header=None)\n",
    "    lll_p.append(dfm.shape[0])\n",
    "    dfm = pd.read_csv(f\"./Input_data/CHS/Test/{i}/random_addshift.bed\", sep=\"\\t\", header=None)\n",
    "    lll_r.append(dfm.shape[0])\n",
    "    dfm = pd.read_csv(f\"./Input_data/CHS/Test/{i}/foreigns.bed\", sep=\"\\t\", header=None)\n",
    "    lll_f.append(dfm.shape[0])\n",
    "    dfm = pd.read_csv(f\"./Input_data/CHS/Test/{i}/shades_addshift.bed\", sep=\"\\t\", header=None)\n",
    "    lll_s.append(dfm.shape[0])\n",
    "    TF_l.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = pd.DataFrame({\"TF_name\":TF_l, \"Seq_count_positives\":lll_p, \"Seq_count_random\":lll_r, \"Seq_count_alien\":lll_f, \"Seq_count_shades\":lll_s})\n",
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.merge(df_total, ddf, on='TF_name', how='left')\n",
    "df_total\n",
    "df_total = df_total.drop_duplicates()\n",
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.to_csv(\"./output/train_on_CHS_predict_on_GHTS_nodup_RF.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
