{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArChIPelag -AggRegating multiple position weight matrices and ChIP-seq with machinE leArninG for prediction of transcription factors binding sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import argparse\n",
    "import subprocess\n",
    "import matplotlib\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pickle\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "import joblib\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from Bio import SeqIO\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import preprocessing\n",
    "import pybedtools as pbt\n",
    "import pyBigWig as pbw\n",
    "import glob\n",
    "from datetime import date\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import chain\n",
    "import string\n",
    "import shlex\n",
    "import shutil\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from adjustText import adjust_text\n",
    "import matplotlib.ticker as ticker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"...\") \n",
    "root = \"...\" \n",
    "basicdir = os.path.abspath('GHTS/') \n",
    "outputdir = os.path.abspath('GHTS/outputdir')\n",
    "train_dir = os.path.abspath('GHTS/Train/') \n",
    "test_dir = os.path.abspath('GHTS/Test/') \n",
    "\n",
    "if not os.path.exists(basicdir): \n",
    "    os.makedirs(basicdir)\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "\n",
    "TFs_CHS_AFS = pd.read_csv(\"....txt\", sep=\"\\t\", header=None)\n",
    "TFs_CHS_AFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "from typing import List\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class Scorer(metaclass=ABCMeta):\n",
    "    name: str\n",
    "    @abstractmethod\n",
    "    def score(self, *args, **kwargs) -> float:\n",
    "        pass\n",
    "\n",
    "@dataclass\n",
    "class ConstantScorer(Scorer):\n",
    "    const: float\n",
    "    def score(self, *args, **kwargs) -> float:\n",
    "        return self.const\n",
    "\n",
    "class BinaryScorer(Scorer):\n",
    "    @abstractmethod\n",
    "    def score(self, y_score: List[float], y_real: List[int]) -> float:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class SklearnScorer(BinaryScorer):\n",
    "    pass\n",
    "\n",
    "class SklearnROCAUC(SklearnScorer):\n",
    "    def score(self, y_score: List[float], y_real: List[int]) -> float:\n",
    "        y_score_arr = np.array(y_score)\n",
    "        y_real_arr = np.array(y_real)\n",
    "        return float(roc_auc_score(y_true=y_real_arr, y_score=y_score_arr))\n",
    "    \n",
    "class SklearnPRAUC(SklearnScorer):\n",
    "    def score(self, y_score: List[float], y_real: List[int]) -> float:\n",
    "        y_score_arr = np.array(y_score)\n",
    "        y_real_arr = np.array(y_real)\n",
    "        return float(average_precision_score(y_true=y_real_arr, y_score=y_score_arr))\n",
    "\n",
    "class PRROCScorer(BinaryScorer):\n",
    "    pass\n",
    "\n",
    "def import_PRROC():\n",
    "    '''\n",
    "    import PRROC package (https://cran.r-project.org/web/packages/PRROC/index.html)\n",
    "    '''\n",
    "    from rpy2.robjects.packages import importr, isinstalled\n",
    "    if not isinstalled(\"PRROC\"):\n",
    "        utils = importr(\"utils\")\n",
    "        utils.chooseCRANmirror(ind=1)\n",
    "        utils.install_packages(\"PRROC\", quiet = True, verbose=False)\n",
    "    pkg = importr(\"PRROC\")\n",
    "    return pkg\n",
    "\n",
    "@dataclass\n",
    "class PRROC_PRAUC(PRROCScorer):\n",
    "    type: str\n",
    "\n",
    "    def score(self, y_score: List[float], y_real: List[int]) -> float:\n",
    "        from rpy2.rinterface_lib import openrlib\n",
    "        with openrlib.rlock:\n",
    "            pkg = import_PRROC()\n",
    "            from rpy2.robjects.vectors import FloatVector\n",
    "            labels = FloatVector([x for x in y_real])\n",
    "            scores = FloatVector(y_score)\n",
    "            if self.type == \"integral\":\n",
    "                auroc = pkg.pr_curve(scores, weights_class0=labels, dg_compute=False)\n",
    "                auroc = auroc[1][0]\n",
    "            elif self.type == \"davisgoadrich\":\n",
    "                auroc = pkg.pr_curve(scores, weights_class0=labels, dg_compute=True)\n",
    "                auroc = auroc[2][0]\n",
    "            else:\n",
    "                raise Exception()\n",
    "            return auroc\n",
    "\n",
    "class PRROC_ROCAUC(PRROCScorer):\n",
    "    def score(self, y_score: List[float], y_real: List[int]) -> float:\n",
    "        from rpy2.rinterface_lib import openrlib\n",
    "        with openrlib.rlock:\n",
    "            pkg = import_PRROC()\n",
    "            from rpy2.robjects.vectors import FloatVector\n",
    "            labels = FloatVector(y_real)\n",
    "            scores = FloatVector(y_score)\n",
    "            auroc = pkg.roc_curve(scores, weights_class0=labels)\n",
    "            auroc = auroc[1][0]\n",
    "            return auroc\n",
    "\n",
    "@dataclass\n",
    "class ScorerInfo:\n",
    "    name: str\n",
    "    alias: str = \"\"\n",
    "    params: dict = field(default_factory=dict)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, dt: dict):\n",
    "        return cls(**dt)\n",
    "\n",
    "    def __attrs_post_init__(self):\n",
    "        if not self.alias:\n",
    "            self.alias = self.name\n",
    "    \n",
    "    def make(self):\n",
    "        if self.name == \"scikit_rocauc\":\n",
    "            return SklearnROCAUC(self.alias)\n",
    "        elif self.name == \"scikit_prauc\":\n",
    "            return SklearnPRAUC(self.alias)\n",
    "        elif self.name == \"prroc_rocauc\":\n",
    "            return PRROC_ROCAUC(self.alias)\n",
    "        elif self.name == \"prroc_prauc\":\n",
    "            tp = self.params.get(\"type\")\n",
    "            if tp is None:\n",
    "                raise Exception(\"type must be specified for prauc scorer from PRROC package\")\n",
    "            tp = tp.lower()\n",
    "            return PRROC_PRAUC(self.alias, tp)\n",
    "        elif self.name == \"constant_scorer\":\n",
    "            cons = self.params.get(\"cons\")\n",
    "            if cons is None:\n",
    "                raise Exception(\"cons must be specified for constant scorer\")\n",
    "            cons = float(cons)\n",
    "            return ConstantScorer(self.alias, cons)\n",
    "        raise Exception(f\"Wrong scorer: {self.name}\")\n",
    "    \n",
    "    def to_dict(self) -> dict:\n",
    "        dt = {}\n",
    "        dt['name'] = self.name\n",
    "        dt['alias'] = self.alias\n",
    "        dt['params'] = self.params\n",
    "        return dt\n",
    "    \n",
    "import scorer_module\n",
    "\n",
    "\n",
    "score_calc_rocauc = ScorerInfo(\"prroc_rocauc\", \"rocauc\").make()\n",
    "\n",
    "score_calc_prauc = ScorerInfo(\"prroc_prauc\", \"prauc\", params={\"type\": \"integral\"}).make()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_building(X_train, X_test, Y_train, Y_test, model_name): \n",
    "\n",
    "    print(\" \")\n",
    "    print(\"Model_building is running ...\")\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "    if model_name == \"RandomForestClassifier\":\n",
    "        MODEL = RandomForestClassifier(**{'max_depth': 6, 'max_features': 4, 'min_samples_leaf': 4, 'min_samples_split': 11, 'n_estimators': 100}, n_jobs=n_jobs)\n",
    "\n",
    "    MODEL.fit(X_train, Y_train)\n",
    "    \n",
    "    return MODEL\n",
    "\n",
    "\n",
    "def rocauc_plotting(X_train_H, X_test_H, Y_train_H, Y_test_H,\n",
    "                    X_test_M, Y_test_M,\n",
    "                    Y_train_predicted_proba_H,\n",
    "                    Y_test_predicted_proba_H,\n",
    "                    Y_test_predicted_proba_M, \n",
    "                    training_obj, testing_obj, \n",
    "                    features_c, \n",
    "                    model_name, \n",
    "                    TF, plot_slim, MODEL, mtrx_di=0, mtrx_mono=0):\n",
    "\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"ROC_AUC_plotting is running ...\")\n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    fig.set_size_inches(16, 10)\n",
    "    linewidth = 5\n",
    "    color_palette = sns.color_palette(\"tab10\")\n",
    "  \n",
    "    f_c_tr_h = 0\n",
    "    best_pwm_q_list = []\n",
    "    best_pwm_number_list = []\n",
    "    for k in range(len(X_train_H.columns)):\n",
    "        f = X_train_H.columns[k]\n",
    "        fpr_train_H_PWM, tpr_train_H_PWM, thresholds = roc_curve(Y_train_H, X_train_H[f])\n",
    "        best_pwm_q_list.append(score_calc_rocauc.score(X_train_H[f], Y_train_H))\n",
    "        best_pwm_number_list.append(k)\n",
    "        \n",
    "    best_pwm_q_list_1, best_pwm_number_list1 = zip(*sorted(zip(best_pwm_q_list, best_pwm_number_list), reverse=True))\n",
    "    f_c_tr_h = best_pwm_number_list1[0]\n",
    "    \n",
    "\n",
    "    f_c_tr_h_pr = 0\n",
    "    best_pwm_q_list = []\n",
    "    best_pwm_number_list = []\n",
    "    for k in range(len(X_train_H.columns)):\n",
    "        f = X_train_H.columns[k]\n",
    "        precision_test_H_m, recall_test_H_m, thresholds = precision_recall_curve(Y_train_H, X_train_H[f])\n",
    "        best_pwm_q_list.append(score_calc_prauc.score(X_train_H[f], Y_train_H))\n",
    "        best_pwm_number_list.append(k)\n",
    "        \n",
    "    best_pwm_q_list_2, best_pwm_number_list2 = zip(*sorted(zip(best_pwm_q_list, best_pwm_number_list), reverse=True))\n",
    "    f_c_tr_h_pr = best_pwm_number_list2[0]\n",
    "    \n",
    "    \n",
    "    best_pwm_q_list = []\n",
    "    best_pwm_number_list = []\n",
    "    for k in range(len(X_train_H.columns)):\n",
    "        f = X_train_H.columns[k]\n",
    "        fpr_train_H_PWM, tpr_train_H_PWM, thresholds = roc_curve(Y_test_M, X_test_M[f])\n",
    "        best_pwm_q_list.append(score_calc_rocauc.score(X_test_M[f], Y_test_M))\n",
    "        best_pwm_number_list.append(k)\n",
    "        \n",
    "    best_pwm_q_list_3, best_pwm_number_list3 = zip(*sorted(zip(best_pwm_q_list, best_pwm_number_list), reverse=True))\n",
    "    \n",
    "    fpr_train_H_PWM, tpr_train_H_PWM, thresholds = roc_curve(Y_train_H, X_train_H[X_train_H.columns[f_c_tr_h]])\n",
    "    roc_auc_train_H_PWM_mono = score_calc_rocauc.score(X_train_H[X_train_H.columns[f_c_tr_h]], Y_train_H)\n",
    "    plt.plot(fpr_train_H_PWM, tpr_train_H_PWM, linewidth=linewidth, label=f'Train PWM {training_obj} ROC (by roc) (AUC = %0.3f)' % roc_auc_train_H_PWM_mono, color=color_palette[0])\n",
    "\n",
    "    \n",
    "    fpr_test_H_PWM, tpr_test_H_PWM, thresholds = roc_curve(Y_test_H, X_test_H[X_test_H.columns[f_c_tr_h]])\n",
    "    roc_auc_test_H_PWM_mono = score_calc_rocauc.score(X_test_H[X_test_H.columns[f_c_tr_h]], Y_test_H)\n",
    "    plt.plot(fpr_test_H_PWM, tpr_test_H_PWM, linewidth=linewidth,label=f'Validation PWM {training_obj} ROC (AUC = %0.3f)' % roc_auc_test_H_PWM_mono, color=color_palette[1])\n",
    "\n",
    "    fpr_test_M_PWM, tpr_test_M_PWM, thresholds = roc_curve(Y_test_M, X_test_M[X_test_M.columns[f_c_tr_h]])\n",
    "    roc_auc_test_M_PWM_mono = score_calc_rocauc.score(X_test_M[X_test_M.columns[f_c_tr_h]], Y_test_M)\n",
    "    plt.plot(fpr_test_M_PWM, tpr_test_M_PWM, linewidth=linewidth,label=f'Validation PWM {testing_obj} ROC (AUC = %0.3f)' % roc_auc_test_M_PWM_mono, color=color_palette[2])\n",
    "\n",
    "    roc_auc_train_H_PWM_di = 0\n",
    "    roc_auc_test_H_PWM_di = 0\n",
    "    roc_auc_test_M_PWM_di = 0\n",
    " \n",
    "    \n",
    "    fpr_test_M, tpr_test_M, thresholds = roc_curve(Y_test_M, Y_test_predicted_proba_M)\n",
    "    roc_auc_test_M = score_calc_rocauc.score(Y_test_predicted_proba_M, Y_test_M)\n",
    "    plt.plot(fpr_test_M, tpr_test_M, linewidth=linewidth,label=f'Validation {model_name}_{mode} {testing_obj} ROC (AUC = %0.3f)' % (roc_auc_test_M), color=color_palette[3])\n",
    "\n",
    "    DF_ROC_PLOTS = pd.DataFrame()\n",
    "    DF_ROC_PLOTS[\"fpr\"] = fpr_test_M\n",
    "    DF_ROC_PLOTS[\"tpr\"] = tpr_test_M\n",
    "    DF_ROC_PLOTS.to_csv(new_dir_name + \"/\" + TF + \"_\" + model_name + \"_\" + str(features_c) + \"_DF_ROC_PLOTS_M_mono_di_test.csv\", sep=\"\\t\", index=False) # записываю \n",
    "\n",
    "\n",
    "    fpr_train_H, tpr_train_H, thresholds = roc_curve(Y_train_H, Y_train_predicted_proba_H)\n",
    "    roc_auc_train_H = score_calc_rocauc.score(Y_train_predicted_proba_H, Y_train_H)\n",
    "    plt.plot(fpr_train_H, tpr_train_H, linewidth=linewidth,label=f'Train {model_name}_{mode} {training_obj} ROC (AUC = %0.3f)' % (roc_auc_train_H), color=color_palette[4])\n",
    "\n",
    "    DF_ROC_PLOTS = pd.DataFrame()\n",
    "    DF_ROC_PLOTS[\"fpr\"] = fpr_train_H\n",
    "    DF_ROC_PLOTS[\"tpr\"] = tpr_train_H\n",
    "    DF_ROC_PLOTS.to_csv(new_dir_name + \"/\" + TF + \"_\" + model_name + \"_\" + str(features_c) + \"_DF_ROC_PLOTS_H_mono_di_train.csv\", sep=\"\\t\", index=False) # записываю \n",
    "\n",
    "    fpr_test_H, tpr_test_H, thresholds = roc_curve(Y_test_H, Y_test_predicted_proba_H)\n",
    "    roc_auc_test_H = score_calc_rocauc.score(Y_test_predicted_proba_H, Y_test_H)\n",
    "    plt.plot(fpr_test_H, tpr_test_H, linewidth=linewidth,label=f'Validation {model_name}_{mode} {training_obj} ROC (AUC = %0.3f)' % (roc_auc_test_H), color=color_palette[5])\n",
    "\n",
    "    DF_ROC_PLOTS = pd.DataFrame()\n",
    "    DF_ROC_PLOTS[\"fpr\"] = fpr_test_H\n",
    "    DF_ROC_PLOTS[\"tpr\"] = tpr_test_H\n",
    "    DF_ROC_PLOTS.to_csv(new_dir_name + \"/\" + TF + \"_\" + model_name + \"_\" + str(features_c) + \"_DF_ROC_PLOTS_H_mono_di_test.csv\", sep=\"\\t\", index=False) # записываю \n",
    "\n",
    "    sns.set_context(\"paper\", font_scale=3)\n",
    "    plt.rc('legend',fontsize=12) # using a size in points\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # ideal classifier\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate', fontsize=25)\n",
    "    plt.ylabel('True Positive Rate', fontsize=25)\n",
    "\n",
    "    \n",
    "    plt.title('{model_name} besthits. {training_obj}/{testing_obj}. {N} features'.format(model_name=model_name, N=features_c, training_obj=training_obj, testing_obj=testing_obj), fontsize=20)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('ROC_AUC_{model_name}_{mode}_Train_{training_obj}_Test_{testing_obj}_{N}_features_{mode}.pdf'.format(mode=mode,model_name=model_name, N=features_c, training_obj=training_obj, testing_obj=testing_obj), dpi=100)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"PR_plotting is running ...\")\n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    fig.set_size_inches(16, 10)\n",
    "\n",
    "    precision_train_H_PWM, recall_train_H_PWM, thresholds = precision_recall_curve(Y_train_H, X_train_H[X_train_H.columns[f_c_tr_h_pr]])\n",
    "    pr_auc_train_H_PWM_mono = score_calc_prauc.score(X_train_H[X_train_H.columns[f_c_tr_h_pr]], Y_train_H)\n",
    "    plt.plot(recall_train_H_PWM, precision_train_H_PWM, linewidth=linewidth,label=f'Train PWM {training_obj} PR (by pr) (AUC = %0.3f)' % pr_auc_train_H_PWM_mono, color=color_palette[0])\n",
    "\n",
    "    \n",
    "    precision_test_H_PWM, recall_test_H_PWM, thresholds = precision_recall_curve(Y_test_H, X_test_H[X_test_H.columns[f_c_tr_h_pr]])\n",
    "    pr_auc_test_H_PWM_mono = score_calc_prauc.score(X_test_H[X_test_H.columns[f_c_tr_h_pr]], Y_test_H)\n",
    "    plt.plot(recall_test_H_PWM, precision_test_H_PWM, linewidth=linewidth,label=f'Validation PWM {training_obj} PR (AUC = %0.3f)' % pr_auc_test_H_PWM_mono, color=color_palette[1])\n",
    "\n",
    "    precision_test_M_PWM, recall_test_M_PWM, thresholds = precision_recall_curve(Y_test_M, X_test_M[X_test_M.columns[f_c_tr_h_pr]])\n",
    "    pr_auc_test_M_PWM_mono = score_calc_prauc.score(X_test_M[X_test_M.columns[f_c_tr_h_pr]], Y_test_M)\n",
    "    plt.plot(recall_test_M_PWM, precision_test_M_PWM, linewidth=linewidth,label=f'Validation PWM {testing_obj} PR (AUC = %0.3f)' % pr_auc_test_M_PWM_mono, color=color_palette[2])\n",
    "\n",
    "\n",
    "    pr_auc_train_H_PWM_di = 0\n",
    "    pr_auc_test_H_PWM_di = 0\n",
    "    pr_auc_test_M_PWM_di = 0\n",
    "\n",
    "    precision_test_M, recall_test_M, thresholds = precision_recall_curve(Y_test_M, Y_test_predicted_proba_M)\n",
    "    pr_auc_test_M = score_calc_prauc.score(Y_test_predicted_proba_M, Y_test_M)\n",
    "    plt.plot(recall_test_M, precision_test_M, linewidth=linewidth,label=f'Validation {testing_obj} PR (AUC = %0.3f )' % (pr_auc_test_M), color=color_palette[3])\n",
    "\n",
    "\n",
    "    DF_PR_PLOTS = pd.DataFrame()\n",
    "    DF_PR_PLOTS[\"precision\"] = precision_test_M\n",
    "    DF_PR_PLOTS[\"recall\"] = recall_test_M\n",
    "    DF_PR_PLOTS.to_csv(new_dir_name + \"/\" + TF + \"_\" + model_name + \"_\" + str(features_c) + \"_DF_PR_PLOTS_M_mono_di_test.csv\", sep=\"\\t\", index=False) # записываю \n",
    "\n",
    "    ##\n",
    "    precision_train_H, recall_train_H, thresholds = precision_recall_curve(Y_train_H, Y_train_predicted_proba_H)\n",
    "    pr_auc_train_H = score_calc_prauc.score(Y_train_predicted_proba_H, Y_train_H)\n",
    "    plt.plot(recall_train_H, precision_train_H, linewidth=linewidth,label=f'Train {training_obj} PR (AUC = %0.3f )' % (pr_auc_train_H), color=color_palette[4])\n",
    "\n",
    "    DF_PR_PLOTS = pd.DataFrame()\n",
    "    DF_PR_PLOTS[\"precision\"] = precision_train_H\n",
    "    DF_PR_PLOTS[\"recall\"] = recall_train_H\n",
    "    DF_PR_PLOTS.to_csv(new_dir_name + \"/\" + TF + \"_\" + model_name + \"_\" + str(features_c) + \"_DF_PR_PLOTS_H_mono_di_train.csv\", sep=\"\\t\", index=False) # записываю \n",
    "\n",
    "    ##\n",
    "    precision_test_H, recall_test_H, thresholds = precision_recall_curve(Y_test_H, Y_test_predicted_proba_H)\n",
    "    pr_auc_test_H = score_calc_prauc.score(Y_test_predicted_proba_H, Y_test_H)\n",
    "    plt.plot(recall_test_H, precision_test_H, linewidth=linewidth,label=f'Validation {training_obj} PR (AUC = %0.3f )' % (pr_auc_test_H), color=color_palette[5])\n",
    "\n",
    "    DF_PR_PLOTS = pd.DataFrame()\n",
    "    DF_PR_PLOTS[\"precision\"] = precision_test_H\n",
    "    DF_PR_PLOTS[\"recall\"] = recall_test_H\n",
    "    DF_PR_PLOTS.to_csv(new_dir_name + \"/\" + TF + \"_\" + model_name + \"_\" + str(features_c) + \"_DF_PR_PLOTS_H_mono_di_test.csv\", sep=\"\\t\", index=False) # записываю \n",
    "\n",
    "    sns.set_context(\"paper\", font_scale=3)\n",
    "    plt.rc('legend',fontsize=12)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('Recall', fontsize=25)\n",
    "    plt.ylabel('Precision', fontsize=25)\n",
    "\n",
    "\n",
    "    plt.title('{model_name} besthits. {training_obj}/{testing_obj}. {N} features'.format(model_name=model_name, N=features_c, training_obj=training_obj, testing_obj=testing_obj), fontsize=20)\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig('PR_AUC_{model_name}_{mode}_Train_{training_obj}_Test_{testing_obj}_{N}_features_{mode}.pdf'.format(mode=mode,model_name=model_name, N=features_c, training_obj=training_obj, testing_obj=testing_obj), dpi=100)\n",
    "\n",
    "\n",
    "    line_f = f'echo {features_c} {roc_auc_train_H_PWM_mono} {roc_auc_train_H_PWM_di} {roc_auc_test_H_PWM_mono} {roc_auc_test_H_PWM_di} {roc_auc_test_M_PWM_mono} {roc_auc_test_M_PWM_di} ' \\\n",
    "                 f'{roc_auc_train_H} 0 0 0 ' \\\n",
    "                 f'{roc_auc_test_H} 0 0 0 ' \\\n",
    "                 f'{roc_auc_test_M} 0 0 0 ' \\\n",
    "                 f'{pr_auc_train_H} 0 0 0 ' \\\n",
    "                 f'{pr_auc_test_H} 0 0 0 ' \\\n",
    "                 f'{pr_auc_test_M} 0 0 0 ' \\\n",
    "                 f'{pr_auc_train_H_PWM_mono} {pr_auc_train_H_PWM_di} {pr_auc_test_H_PWM_mono} {pr_auc_test_H_PWM_di} {pr_auc_test_M_PWM_mono} {pr_auc_test_M_PWM_di} ' \\\n",
    "             f' >> {TF}_new_log_roc_pr_{mode}_{today_date}.txt'\n",
    "    p = subprocess.Popen(line_f, shell=True)\n",
    "    p.wait()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def Scale_transform(X, scale_data):\n",
    "    if scale_data == True:\n",
    "        X_out = X.copy()\n",
    "        scaler = StandardScaler()\n",
    "        scaler_fit = scaler.fit(X_out)\n",
    "\n",
    "        print(\"mean\", scaler_fit.mean_)\n",
    "        print(\"var\", scaler_fit.var_)\n",
    "        \n",
    "        \n",
    "        X_out = pd.DataFrame(scaler_fit.transform(X_out), columns = X_out.columns)\n",
    "        X = []\n",
    "        return X_out\n",
    "    else:\n",
    "        X_out = X.copy()\n",
    "        X = []\n",
    "        return X_out\n",
    "\n",
    "    \n",
    "def scrambled(orig):\n",
    "    dest = orig[:]\n",
    "    shuffle(dest)\n",
    "    return dest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "\n",
    "def collect_all_scanning_res(TF, exp, dataset, flag, root, mode, model_name, pwm_scanning_res_list):\n",
    "    pwmdir = f\"{exp}/{dataset}/{TF}/pwm_scanning_results_addshift\"\n",
    "    pwm_scanning_res_list_flaged = [x + f\"_{flag}_cut.tab\" for x in pwm_scanning_res_list]\n",
    "\n",
    "    df_collector = []\n",
    "    for file_name in pwm_scanning_res_list_flaged:\n",
    "        dftmp = pd.read_csv(f\"{root}/{pwmdir}/{file_name}\", header=None, sep='\\t')[0]\n",
    "        df_collector.append(dftmp)\n",
    "    \n",
    "    df = pd.DataFrame({i:j for i,j in enumerate(df_collector)})\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def collect_all_scanning_res_CHS_scanning_with_GHTS_pwm(TF, exp, dataset, flag, root, mode, model_name, pwm_scanning_res_list):\n",
    "    pwmdir = f\"{exp}/{dataset}/{TF}/pwm_scanning_results_CHS_scanning_with_GHTS_pwm_addshift\"\n",
    "    pwm_scanning_res_list_flaged = [x + f\"_{flag}_cut.tab\" for x in pwm_scanning_res_list]\n",
    "\n",
    "    df_collector = []\n",
    "    for file_name in pwm_scanning_res_list_flaged:\n",
    "        dftmp = pd.read_csv(f\"{root}/{pwmdir}/{file_name}\", header=None, sep='\\t')[0]\n",
    "        df_collector.append(dftmp)\n",
    "    \n",
    "    df = pd.DataFrame({i:j for i,j in enumerate(df_collector)})\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def collect_all_scanning_res_GHTS_scanning_with_CHS_pwm(TF, exp, dataset, flag, root, mode, model_name, pwm_scanning_res_list):\n",
    "    pwmdir = f\"{exp}/{dataset}/{TF}/pwm_scanning_results_GHTS_scanning_with_CHS_pwm_addshift\"\n",
    "\n",
    "    pwm_scanning_res_list_flaged = [x + f\"_{flag}_cut.tab\" for x in pwm_scanning_res_list]\n",
    "    \n",
    "    df_collector = []\n",
    "    for file_name in pwm_scanning_res_list_flaged:\n",
    "        dftmp = pd.read_csv(f\"{root}/{pwmdir}/{file_name}\", header=None, sep='\\t')[0]\n",
    "        df_collector.append(dftmp)\n",
    "    \n",
    "    df = pd.DataFrame({i:j for i,j in enumerate(df_collector)})\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "organism = \"HUMAN_CHS_GHTS\"\n",
    "n_jobs = 100\n",
    "scale_data = True\n",
    "print_GC = False\n",
    "verbose = True\n",
    "\n",
    "#today = date.today()\n",
    "#today_date = today.strftime(\"%d.%m.%Y\")\n",
    "today_date = \"23.12.2023\"\n",
    "    \n",
    "\n",
    "mode  = \"mono\"\n",
    "model_name  = \"RandomForestClassifier\"\n",
    "sys.setrecursionlimit = 10**3 \n",
    "\n",
    "\n",
    "root = \"...\"\n",
    "os.chdir(root)\n",
    "\n",
    "model_dir = os.path.abspath('...') \n",
    "basicdir = model_dir\n",
    "new_dir_name = model_dir\n",
    "\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "os.chdir(model_dir)\n",
    "\n",
    "\n",
    "TF_сalc = 0\n",
    "for TF in files_pwm_HUMAN_mono:   \n",
    "    print(\" \")\n",
    "    print(f\"{TF} #\" + \" {сalc} of {all_c}\".format(all_c=len(files_pwm_HUMAN_mono), сalc=TF_сalc))\n",
    "    TF_сalc += 1\n",
    "\n",
    "    pwmdir_mono = \"/home/ivankozin/projects/best_20_motif_CHS_AFS/AFS\"\n",
    "    dir_list = os.listdir(pwmdir_mono + \"/\" + TF) \n",
    "    pwm_scanning_res_list = []\n",
    "\n",
    "    for exp_pwm_dir in dir_list:\n",
    "        pwm_local_dir = pwmdir_mono + \"/\" + TF + \"/\" + exp_pwm_dir\n",
    "        pwm_local_list = [x.split(\".pwm\")[0] for x in os.listdir(pwm_local_dir) if \"pwm\" in x]\n",
    "        pwm_scanning_res_list.extend(pwm_local_list)\n",
    "\n",
    "\n",
    "    pwm_scanning_res_list = list(set(pwm_scanning_res_list))\n",
    "\n",
    "    df_pos = collect_all_scanning_res(TF, \"GHTS\", \"Train\", \"positives\", root, mode, model_name, pwm_scanning_res_list)\n",
    "    df_neg = collect_all_scanning_res(TF, \"GHTS\", \"Train\", \"random\", root, mode, model_name, pwm_scanning_res_list)\n",
    "\n",
    "    df_pos[\"ind\"] = 1\n",
    "    df_neg[\"ind\"] = 0\n",
    "    df = pd.concat([df_pos, df_neg])\n",
    "    \n",
    "    X_train_GHTS, Y_train_GHTS = df.iloc[:,:-1], df[\"ind\"]\n",
    "    \n",
    "    X_out = X_train_GHTS.copy()\n",
    "    scaler = StandardScaler()\n",
    "    scaler_fit = scaler.fit(X_out)\n",
    "    \n",
    "    X_train_GHTS = pd.DataFrame(scaler_fit.transform(X_train_GHTS), columns = X_train_GHTS.columns)\n",
    "    \n",
    "    df_pos = collect_all_scanning_res(TF, \"GHTS\", \"Test\", \"positives\", root, mode, model_name, pwm_scanning_res_list)\n",
    "    df_neg = collect_all_scanning_res(TF, \"GHTS\", \"Test\", \"random\", root, mode, model_name, pwm_scanning_res_list)\n",
    "    \n",
    "    df_pos[\"ind\"] = 1\n",
    "    df_neg[\"ind\"] = 0\n",
    "    df = pd.concat([df_pos, df_neg])\n",
    "    \n",
    "    X_test_GHTS, Y_test_GHTS = df.iloc[:,:-1], df[\"ind\"]\n",
    "    X_test_GHTS = pd.DataFrame(scaler_fit.transform(X_test_GHTS), columns = X_test_GHTS.columns)\n",
    "    \n",
    "    df_pos = collect_all_scanning_res_CHS_scanning_with_GHTS_pwm(TF, \"CHS\", \"Test\", \"positives\", root, mode, model_name, pwm_scanning_res_list)\n",
    "    df_neg = collect_all_scanning_res_CHS_scanning_with_GHTS_pwm(TF, \"CHS\", \"Test\", \"random\", root, mode, model_name, pwm_scanning_res_list)\n",
    "    \n",
    "    df_pos[\"ind\"] = 1\n",
    "    df_neg[\"ind\"] = 0\n",
    "    df = pd.concat([df_pos, df_neg])\n",
    "    \n",
    "    X_test_CHS, Y_test_CHS = df.iloc[:,:-1], df[\"ind\"]\n",
    "    X_test_CHS = pd.DataFrame(scaler_fit.transform(X_test_CHS), columns = X_test_CHS.columns)\n",
    "    \n",
    "    MODEL = model_building(X_train_GHTS, X_test_GHTS, Y_train_GHTS, Y_test_GHTS, model_name)\n",
    "    \n",
    "    filename = f\"{basicdir}/{TF}_trained_model.sav\"\n",
    "    pickle.dump(MODEL, open(filename, 'wb'))\n",
    "\n",
    "    \n",
    "    Y_train_predicted_proba_GHTS = MODEL.predict_proba(X_train_GHTS)[:, 1]\n",
    "    Y_test_predicted_proba_GHTS = MODEL.predict_proba(X_test_GHTS)[:, 1]\n",
    "    Y_test_predicted_proba_CHS = MODEL.predict_proba(X_test_CHS)[:, 1]\n",
    "        \n",
    "     \n",
    "    rocauc_plotting(X_train_GHTS, X_test_GHTS, Y_train_GHTS, Y_test_GHTS,\n",
    "                            X_test_CHS, Y_test_CHS,\n",
    "                            Y_train_predicted_proba_GHTS,\n",
    "                            Y_test_predicted_proba_GHTS,\n",
    "                            Y_test_predicted_proba_CHS, \n",
    "                            \"GHTS\", \n",
    "                            \"CHS\", \n",
    "                            X_test_CHS.shape[1], \n",
    "                            model_name + \" on \" + TF, \n",
    "                            TF, False, MODEL)\n",
    "    \n",
    "    \n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
