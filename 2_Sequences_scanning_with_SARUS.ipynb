{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scanning with SARUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import argparse\n",
    "import subprocess\n",
    "import matplotlib\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import shlex\n",
    "import shutil\n",
    "import glob\n",
    "import pickle\n",
    "import csv\n",
    "import operator\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from collections import defaultdict\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from Bio import SeqIO\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import preprocessing\n",
    "import pybedtools as pbt\n",
    "import pyBigWig as pbw\n",
    "from datetime import date\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import chain\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from adjustText import adjust_text\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scanning GHTS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"[your path to dir]/MEX-ArChIPelago/\" \n",
    "basicdir = os.path.abspath('GHTS/')\n",
    "outputdir = os.path.abspath('GHTS/outputdir')\n",
    "train_dir = os.path.abspath('GHTS/Train/') \n",
    "test_dir = os.path.abspath('GHTS/Test/') \n",
    "\n",
    "if not os.path.exists(basicdir): \n",
    "    os.makedirs(basicdir)\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "\n",
    "\n",
    "TFs_CHS_AFS = pd.read_csv(\"./Input_data/best_20_motif_CHS_GHTS.txt\", sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(42)\n",
    "model = \"RandomForestClassifier\"\n",
    "organism = \"HUMAN_GHTS\"\n",
    "sarsus_home = \"\" # if you wish to use a specific release, please specify ./sarus/releases/sarus-x.x.x.jar\n",
    "pwmdir_mono = \"./Input_data/best_20_motif_CHS_GHTS/GHTS\"\n",
    "\n",
    "TF_dir = train_dir\n",
    "\n",
    "print(\" \")\n",
    "сalc = 0\n",
    "for TF in sorted(TFs_CHS_AFS):  # For DEMO tests use [\"GABPA\"] instead of TFs_CHS_AFS. \n",
    "    print(TF)\n",
    "    print(\"TF # {сalc} of {all_c}\".format(all_c=len(TFs_CHS_AFS), сalc=сalc))\n",
    "    сalc += 1\n",
    "\n",
    "    print(\"Dirname is:\", TF)\n",
    "\n",
    "    new_dir_name = f\"{TF_dir}/{TF}/pwm_scanning_results_addshift\"\n",
    "    print(\"New_dir_name\", new_dir_name)\n",
    "\n",
    "    if not os.path.exists(new_dir_name):\n",
    "        os.makedirs(new_dir_name)\n",
    "\n",
    "    os.chdir(new_dir_name)\n",
    "    dir_list = os.listdir(pwmdir_mono + \"/\" + TF)\n",
    "\n",
    "    print(\"dir_list\", len(dir_list))\n",
    "    for exp_pwm_dir in dir_list:\n",
    "        pwm_local_dir = pwmdir_mono + \"/\" + TF + \"/\" + exp_pwm_dir\n",
    "        pwm_local_list = [x for x in os.listdir(pwm_local_dir) if \"pwm\" in x]\n",
    "        print(\"Sarus is running ...\")\n",
    "        for matrix in pwm_local_list:\n",
    "\n",
    "            line = 'java -Xmx2G -cp {sarsus_home} ru.autosome.SARUS {mfa_file} {matrix} --skipn --show-non-matching --output-scoring-mode score besthit | grep -v \\> > {out_file}'.format(sarsus_home = root + \"/sarus/releases/sarus-2.0.1.jar\",\n",
    "            mfa_file = '/'.join([TF_dir, TF, \"positives_no_NF.fa\"]),\n",
    "            matrix = '/'.join([pwm_local_dir, matrix]),\n",
    "            out_file = '/'.join([new_dir_name, \".\".join(matrix.split(\".\")[:-1]) + \"_positives.tab\"]))\n",
    "\n",
    "            p = subprocess.Popen(line, shell=True)\n",
    "            p.wait()\n",
    "                     \n",
    "            !rm tmp.sh\n",
    "\n",
    "            line1 = \"awk -F. \\'{print $1\\\".\\\"substr($2,1,2)}\\' \" + \".\".join(matrix.split(\".\")[:-1]) + \"_positives.tab\" + \" > \" + \".\".join(matrix.split(\".\")[:-1]) + \"_positives_cut.tab\"\n",
    "            line2 = \"rm \" + \".\".join(matrix.split(\".\")[:-1]) + \"_positives.tab\"\n",
    "\n",
    "            with open(\"tmp.sh\", \"w\") as f:\n",
    "                f.write(line1)\n",
    "                f.write(\" ; \")\n",
    "                f.write(line2)\n",
    "            !bash tmp.sh\n",
    "\n",
    "            line = 'java -Xmx2G -cp {sarsus_home} ru.autosome.SARUS {mfa_file} {matrix} --skipn --show-non-matching --output-scoring-mode score besthit | grep -v \\> > {out_file}'.format(sarsus_home = root + \"/sarus/releases/sarus-2.0.1.jar\",\n",
    "            mfa_file = '/'.join([TF_dir, TF, \"foreigns_no_NF.fa\"]),\n",
    "            matrix = '/'.join([pwm_local_dir, matrix]),\n",
    "            out_file = '/'.join([new_dir_name, \".\".join(matrix.split(\".\")[:-1]) + \"_foreigns.tab\"]))\n",
    "\n",
    "            p = subprocess.Popen(line, shell=True)\n",
    "            p.wait()\n",
    "            \n",
    "            !rm tmp.sh\n",
    "\n",
    "            line1 = \"awk -F. \\'{print $1\\\".\\\"substr($2,1,2)}\\' \" + \".\".join(matrix.split(\".\")[:-1]) + \"_foreigns.tab\" + \" > \" + \".\".join(matrix.split(\".\")[:-1]) + \"_foreigns_cut.tab\"\n",
    "            line2 = \"rm \" + \".\".join(matrix.split(\".\")[:-1]) + \"_foreigns.tab\"\n",
    "\n",
    "            with open(\"tmp.sh\", \"w\") as f:\n",
    "                f.write(line1)\n",
    "                f.write(\" ; \")\n",
    "                f.write(line2)\n",
    "            !bash tmp.sh\n",
    "            !rm tmp.sh\n",
    "            \n",
    "            line = 'java -Xmx2G -cp {sarsus_home} ru.autosome.SARUS {mfa_file} {matrix} --skipn --show-non-matching --output-scoring-mode score besthit | grep -v \\> > {out_file}'.format(sarsus_home = root + \"/sarus/releases/sarus-2.0.1.jar\",\n",
    "            mfa_file = '/'.join([TF_dir, TF, \"random_no_NF.fa\"]),\n",
    "            matrix = '/'.join([pwm_local_dir, matrix]),\n",
    "            out_file = '/'.join([new_dir_name, \".\".join(matrix.split(\".\")[:-1]) + \"_random.tab\"]))\n",
    "            #print(line)\n",
    "\n",
    "            p = subprocess.Popen(line, shell=True)\n",
    "            p.wait()\n",
    "                 \n",
    "            !rm tmp.sh\n",
    "\n",
    "            line1 = \"awk -F. \\'{print $1\\\".\\\"substr($2,1,2)}\\' \" + \".\".join(matrix.split(\".\")[:-1]) + \"_random.tab\" + \" > \" + \".\".join(matrix.split(\".\")[:-1]) + \"_random_cut.tab\"\n",
    "            line2 = \"rm \" + \".\".join(matrix.split(\".\")[:-1]) + \"_random.tab\"\n",
    "\n",
    "            with open(\"tmp.sh\", \"w\") as f:\n",
    "                f.write(line1)\n",
    "                f.write(\" ; \")\n",
    "                f.write(line2)\n",
    "            !bash tmp.sh\n",
    "            !rm tmp.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scanning CHS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basicdir = os.path.abspath('CHS/')\n",
    "outputdir = os.path.abspath('CHS/outputdir')\n",
    "train_dir = os.path.abspath('CHS/Train/') \n",
    "test_dir = os.path.abspath('CHS/Test/') \n",
    "\n",
    "if not os.path.exists(basicdir): \n",
    "    os.makedirs(basicdir)\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(42)\n",
    "model = \"RandomForestClassifier\"\n",
    "organism = \"HUMAN_CHS\"\n",
    "sarsus_home = \"\" # if you wish to use a specific release, please specify ./sarus/releases/sarus-x.x.x.jar\n",
    "pwmdir_mono = \"./Input_data/best_20_motif_CHS_GHTS/CHS\"\n",
    "\n",
    "TF_dir = train_dir\n",
    "\n",
    "print(\" \")\n",
    "сalc = 0\n",
    "for TF in sorted(TFs_CHS_AFS):  # For DEMO tests use [\"GABPA\"] instead of TFs_CHS_AFS. \n",
    "    print(TF)\n",
    "    print(\"TF # {сalc} of {all_c}\".format(all_c=len(TFs_CHS_AFS), сalc=сalc))\n",
    "    сalc += 1\n",
    "\n",
    "    print(\"Dirname is:\", TF)\n",
    "\n",
    "    new_dir_name = f\"{TF_dir}/{TF}/pwm_scanning_results_addshift\"\n",
    "    print(\"New_dir_name\", new_dir_name)\n",
    "\n",
    "    if not os.path.exists(new_dir_name):\n",
    "        os.makedirs(new_dir_name)\n",
    "\n",
    "    os.chdir(new_dir_name)\n",
    "    dir_list = os.listdir(pwmdir_mono + \"/\" + TF)\n",
    "\n",
    "    print(\"dir_list\", len(dir_list))\n",
    "    for exp_pwm_dir in dir_list:\n",
    "        pwm_local_dir = pwmdir_mono + \"/\" + TF + \"/\" + exp_pwm_dir\n",
    "        pwm_local_list = [x for x in os.listdir(pwm_local_dir) if \"pwm\" in x]\n",
    "        print(\"Sarus is running ...\")\n",
    "        for matrix in pwm_local_list:\n",
    "\n",
    "            line = 'java -Xmx2G -cp {sarsus_home} ru.autosome.SARUS {mfa_file} {matrix} --skipn --show-non-matching --output-scoring-mode score besthit | grep -v \\> > {out_file}'.format(sarsus_home = root + \"/sarus/releases/sarus-2.0.1.jar\",\n",
    "            mfa_file = '/'.join([TF_dir, TF, \"positives_no_NF.fa\"]),\n",
    "            matrix = '/'.join([pwm_local_dir, matrix]),\n",
    "            out_file = '/'.join([new_dir_name, \".\".join(matrix.split(\".\")[:-1]) + \"_positives.tab\"]))\n",
    "\n",
    "            p = subprocess.Popen(line, shell=True)\n",
    "            p.wait()\n",
    "                     \n",
    "            !rm tmp.sh\n",
    "\n",
    "            line1 = \"awk -F. \\'{print $1\\\".\\\"substr($2,1,2)}\\' \" + \".\".join(matrix.split(\".\")[:-1]) + \"_positives.tab\" + \" > \" + \".\".join(matrix.split(\".\")[:-1]) + \"_positives_cut.tab\"\n",
    "            line2 = \"rm \" + \".\".join(matrix.split(\".\")[:-1]) + \"_positives.tab\"\n",
    "\n",
    "            with open(\"tmp.sh\", \"w\") as f:\n",
    "                f.write(line1)\n",
    "                f.write(\" ; \")\n",
    "                f.write(line2)\n",
    "            !bash tmp.sh\n",
    "\n",
    "            line = 'java -Xmx2G -cp {sarsus_home} ru.autosome.SARUS {mfa_file} {matrix} --skipn --show-non-matching --output-scoring-mode score besthit | grep -v \\> > {out_file}'.format(sarsus_home = root + \"/sarus/releases/sarus-2.0.1.jar\",\n",
    "            mfa_file = '/'.join([TF_dir, TF, \"foreigns_no_NF.fa\"]),\n",
    "            matrix = '/'.join([pwm_local_dir, matrix]),\n",
    "            out_file = '/'.join([new_dir_name, \".\".join(matrix.split(\".\")[:-1]) + \"_foreigns.tab\"]))\n",
    "\n",
    "            p = subprocess.Popen(line, shell=True)\n",
    "            p.wait()\n",
    "            \n",
    "            !rm tmp.sh\n",
    "\n",
    "            line1 = \"awk -F. \\'{print $1\\\".\\\"substr($2,1,2)}\\' \" + \".\".join(matrix.split(\".\")[:-1]) + \"_foreigns.tab\" + \" > \" + \".\".join(matrix.split(\".\")[:-1]) + \"_foreigns_cut.tab\"\n",
    "            line2 = \"rm \" + \".\".join(matrix.split(\".\")[:-1]) + \"_foreigns.tab\"\n",
    "\n",
    "            with open(\"tmp.sh\", \"w\") as f:\n",
    "                f.write(line1)\n",
    "                f.write(\" ; \")\n",
    "                f.write(line2)\n",
    "            !bash tmp.sh\n",
    "            !rm tmp.sh\n",
    "            \n",
    "            line = 'java -Xmx2G -cp {sarsus_home} ru.autosome.SARUS {mfa_file} {matrix} --skipn --show-non-matching --output-scoring-mode score besthit | grep -v \\> > {out_file}'.format(sarsus_home = root + \"/sarus/releases/sarus-2.0.1.jar\",\n",
    "            mfa_file = '/'.join([TF_dir, TF, \"random_no_NF.fa\"]),\n",
    "            matrix = '/'.join([pwm_local_dir, matrix]),\n",
    "            out_file = '/'.join([new_dir_name, \".\".join(matrix.split(\".\")[:-1]) + \"_random.tab\"]))\n",
    "            #print(line)\n",
    "\n",
    "            p = subprocess.Popen(line, shell=True)\n",
    "            p.wait()\n",
    "                 \n",
    "            !rm tmp.sh\n",
    "\n",
    "            line1 = \"awk -F. \\'{print $1\\\".\\\"substr($2,1,2)}\\' \" + \".\".join(matrix.split(\".\")[:-1]) + \"_random.tab\" + \" > \" + \".\".join(matrix.split(\".\")[:-1]) + \"_random_cut.tab\"\n",
    "            line2 = \"rm \" + \".\".join(matrix.split(\".\")[:-1]) + \"_random.tab\"\n",
    "\n",
    "            with open(\"tmp.sh\", \"w\") as f:\n",
    "                f.write(line1)\n",
    "                f.write(\" ; \")\n",
    "                f.write(line2)\n",
    "            !bash tmp.sh\n",
    "            !rm tmp.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
