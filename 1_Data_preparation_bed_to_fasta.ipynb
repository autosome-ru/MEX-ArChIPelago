{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import argparse\n",
    "import subprocess\n",
    "import matplotlib\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pickle\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "import joblib\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from Bio import SeqIO\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import preprocessing\n",
    "import pybedtools as pbt\n",
    "import pyBigWig as pbw\n",
    "import glob\n",
    "from datetime import date\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import chain\n",
    "import string\n",
    "import shlex\n",
    "import shutil\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from adjustText import adjust_text\n",
    "import matplotlib.ticker as ticker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"...\") \n",
    "root = \"...\" \n",
    "basicdir = os.path.abspath('GHTS/') \n",
    "outputdir = os.path.abspath('GHTS/outputdir')\n",
    "train_dir = os.path.abspath('GHTS/Train/') \n",
    "test_dir = os.path.abspath('GHTS/Test/') \n",
    "\n",
    "if not os.path.exists(basicdir): \n",
    "    os.makedirs(basicdir)\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFs_CHS_AFS = pd.read_csv(\"....txt\", sep=\"\\t\", header=None)\n",
    "TFs_CHS_AFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta = pbt.example_filename('../hg38.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"../pbt_exclusion_zone\"):\n",
    "    os.makedirs(\"../pbt_exclusion_zone\")\n",
    "pbt.helpers.set_tempdir(\"../pbt_exclusion_zone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [x for x in os.listdir(\".../Test/\") if x in list(TFs_CHS_AFS[0])]:\n",
    "    print(test_dir+\"/\"+i)\n",
    "    if not os.path.exists(test_dir+\"/\"+i):\n",
    "        os.makedirs(test_dir+\"/\"+i)\n",
    "    for j in os.listdir(\".../Test/\"+i):\n",
    "        #print(j)\n",
    "        dfm = pd.read_csv(f\".../Test/{i}/foreigns.bed\", sep=\"\\t\", header=None)\n",
    "        foreigns = pbt.BedTool.from_dataframe(dfm)\n",
    "        foreigns = foreigns.sequence(fi=fasta)\n",
    "        foreigns_fa = open(foreigns.seqfn).read()\n",
    "        with open(test_dir+\"/\"+i+\"/foreigns.fa\", \"w\") as f:\n",
    "            f.write(foreigns_fa)\n",
    "            \n",
    "        dfm = pd.read_csv(f\".../Test/{i}/positives.bed\", sep=\"\\t\", header=None)\n",
    "        positives = pbt.BedTool.from_dataframe(dfm)\n",
    "        positives = positives.sequence(fi=fasta)\n",
    "        positives_fa = open(positives.seqfn).read()\n",
    "        with open(test_dir+\"/\"+i+\"/positives.fa\", \"w\") as f:\n",
    "            f.write(positives_fa)\n",
    "        \n",
    "        dfm = pd.read_csv(f\".../Test/{i}/random.bed\", sep=\"\\t\", header=None)\n",
    "        random = pbt.BedTool.from_dataframe(dfm)\n",
    "        random = random.sequence(fi=fasta)\n",
    "        random_fa = open(random.seqfn).read()\n",
    "        with open(test_dir+\"/\"+i+\"/random.fa\", \"w\") as f:\n",
    "            f.write(random_fa)\n",
    "        \n",
    "        dfm = pd.read_csv(f\"../Test/{i}/shades.bed\", sep=\"\\t\", header=None)\n",
    "        shades = pbt.BedTool.from_dataframe(dfm)\n",
    "        shades = shades.sequence(fi=fasta)\n",
    "        shades_fa = open(shades.seqfn).read()\n",
    "        with open(test_dir+\"/\"+i+\"/shades.fa\", \"w\") as f:\n",
    "            f.write(shades_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [x for x in os.listdir(\".../Train/\") if x in list(TFs_CHS_AFS[0])]:\n",
    "    print(train_dir+\"/\"+i)\n",
    "    if not os.path.exists(train_dir+\"/\"+i): # если нет result, то создаем\n",
    "        os.makedirs(train_dir+\"/\"+i)\n",
    "    for j in os.listdir(\".../Train/\"+i):\n",
    "        #print(j)\n",
    "        dfm = pd.read_csv(f\".../Train/{i}/foreigns.bed\", sep=\"\\t\", header=None)\n",
    "        foreigns = pbt.BedTool.from_dataframe(dfm)\n",
    "        foreigns = foreigns.sequence(fi=fasta)\n",
    "        foreigns_fa = open(foreigns.seqfn).read()\n",
    "        with open(train_dir+\"/\"+i+\"/foreigns.fa\", \"w\") as f:\n",
    "            f.write(foreigns_fa)\n",
    "            \n",
    "        dfm = pd.read_csv(f\".../Train/{i}/positives.bed\", sep=\"\\t\", header=None)\n",
    "        positives = pbt.BedTool.from_dataframe(dfm)\n",
    "        positives = positives.sequence(fi=fasta)\n",
    "        positives_fa = open(positives.seqfn).read()\n",
    "        with open(train_dir+\"/\"+i+\"/positives.fa\", \"w\") as f:\n",
    "            f.write(positives_fa)\n",
    "        \n",
    "        dfm = pd.read_csv(f\".../Train/{i}/random_addshift.bed\", sep=\"\\t\", header=None)\n",
    "        random = pbt.BedTool.from_dataframe(dfm)\n",
    "        random = random.sequence(fi=fasta)\n",
    "        random_fa = open(random.seqfn).read()\n",
    "        with open(train_dir+\"/\"+i+\"/random.fa\", \"w\") as f:\n",
    "            f.write(random_fa)\n",
    "        \n",
    "        dfm = pd.read_csv(f\".../GHTS/Train/{i}/shades_addshift.bed\", sep=\"\\t\", header=None)\n",
    "        shades = pbt.BedTool.from_dataframe(dfm)\n",
    "        shades = shades.sequence(fi=fasta)\n",
    "        shades_fa = open(shades.seqfn).read()\n",
    "        with open(train_dir+\"/\"+i+\"/shades.fa\", \"w\") as f:\n",
    "            f.write(shades_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [x for x in os.listdir(\".../Test/\") if x in list(TFs_CHS_AFS[0])]:\n",
    "    print(test_dir+\"/\"+i)\n",
    "    if not os.path.exists(test_dir+\"/\"+i): # если нет result, то создаем\n",
    "        os.makedirs(test_dir+\"/\"+i)\n",
    "    for j in os.listdir(\".../Test/\"+i):\n",
    "\n",
    "        line = f\"awk 'NF' {test_dir}/{i}/positives.fa > {test_dir}/{i}/positives_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()\n",
    "        line = f\"awk 'NF' {test_dir}/{i}/foreigns.fa > {test_dir}/{i}/foreigns_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()\n",
    "        \n",
    "        line = f\"awk 'NF' {test_dir}/{i}/random.fa > {test_dir}/{i}/random_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()\n",
    "\n",
    "        line = f\"awk 'NF' {test_dir}/{i}/shades.fa > {test_dir}/{i}/shades_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [x for x in os.listdir(\".../Train/\") if x in list(TFs_CHS_AFS[0])]:\n",
    "    print(train_dir+\"/\"+i)\n",
    "    if not os.path.exists(train_dir+\"/\"+i): # если нет result, то создаем\n",
    "        os.makedirs(train_dir+\"/\"+i)\n",
    "    for j in os.listdir(\".../Train/\"+i):\n",
    "\n",
    "        line = f\"awk 'NF' {train_dir}/{i}/positives.fa > {train_dir}/{i}/positives_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()\n",
    "        line = f\"awk 'NF' {train_dir}/{i}/foreigns.fa > {train_dir}/{i}/foreigns_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()\n",
    "        \n",
    "        line = f\"awk 'NF' {train_dir}/{i}/random.fa > {train_dir}/{i}/random_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()\n",
    "\n",
    "        line = f\"awk 'NF' {train_dir}/{i}/shades.fa > {train_dir}/{i}/shades_no_NF.fa\"\n",
    "        print(line)\n",
    "        p = subprocess.Popen(line, shell=True)\n",
    "        p.wait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
